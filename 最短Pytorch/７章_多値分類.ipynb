{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "最短Pytorchの導入.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPlVAvvCSZ9XOW60EjjR5r9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/newstage75/ML_study/blob/master/%E6%9C%80%E7%9F%ADPytorch/%EF%BC%97%E7%AB%A0_%E5%A4%9A%E5%80%A4%E5%88%86%E9%A1%9E.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#７章_多値分類"
      ],
      "metadata": {
        "id": "CEgOOTrGJU31"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48AexnpDJAMO",
        "outputId": "5cc2c0c9-8dbd-4ffe-bb1a-5f17529599c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed japanize-matplotlib-1.1.3\n",
            "Successfully installed torchviz-0.0.2\n",
            "Successfully installed torchinfo-1.6.6\n"
          ]
        }
      ],
      "source": [
        "# 必要ライブラリの導入\n",
        "\n",
        "!pip install japanize_matplotlib | tail -n 1\n",
        "!pip install torchviz | tail -n 1\n",
        "!pip install torchinfo | tail -n 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 必要ライブラリのインポート\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import japanize_matplotlib\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "ghCJoyn3JbCd"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch関連ライブラリのインポート\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchinfo import summary\n",
        "from torchviz import make_dot"
      ],
      "metadata": {
        "id": "wJKfNpszLiia"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# デフォルトフォントサイズ変更\n",
        "plt.rcParams['font.size'] = 14\n",
        "\n",
        "# デフォルトグラフサイズ変更\n",
        "plt.rcParams['figure.figsize'] = (6,6)\n",
        "\n",
        "# デフォルトで方眼表示ON\n",
        "plt.rcParams['axes.grid'] = True\n",
        "\n",
        "# numpyの表示桁数設定\n",
        "np.set_printoptions(suppress=True, precision=4)"
      ],
      "metadata": {
        "id": "TTSBA8aYJeL0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#データ読み込み\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "x_org, y_org = iris.data, iris.target\n",
        "\n",
        "print('元データ', x_org.shape, y_org.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dLf0lhQDXtpQ",
        "outputId": "9fc4c72f-6f46-4af4-ef6c-8915709ac62f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "元データ (150, 4) (150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_org[:5,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_z5uJfhOYIoE",
        "outputId": "ca52861a-da23-4808-a6f8-e85743fbe968"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1列目と3列目にしぼる(がく片（sepal）と花弁(petal)のlengtn)\n",
        "x_select = x_org[:,[0,2]]\n",
        "\n",
        "print('元データ', x_select.shape, y_org.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ae88k08X_Q6",
        "outputId": "316f51ab-7a9a-4efe-ef53-4acf0c116db8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "元データ (150, 2) (150,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_select, y_org, train_size=75, test_size=75,\n",
        "    random_state=123)\n",
        "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kUr6Z6pYm33",
        "outputId": "f678ea2e-c404-480c-933d-3f0deb56f203"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(75, 2) (75, 2) (75,) (75,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#　データを正解値ごとに分割\n",
        "\n",
        "x_t0 = x_train[y_train == 0]\n",
        "x_t1 = x_train[y_train == 1]\n",
        "x_t2 = x_train[y_train == 2]"
      ],
      "metadata": {
        "id": "Dyivbb5Qdkb1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 散布図の表示\n",
        "plt.scatter(x_t0[:,0],x_t0[:,1],marker='x', c='k', s=50, label='0(setosa)')\n",
        "plt.scatter(x_t1[:,0],x_t1[:,1],marker='o', c='b', s=50, label='1(versicolour)')\n",
        "plt.scatter(x_t2[:,0],x_t2[:,1],marker='+', c='k', s=50, label='2(virginica)')\n",
        "plt.xlabel('sepal_length')\n",
        "plt.ylabel('petal_length')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bk_a_uJUeJbs",
        "outputId": "437a14d3-472d-4b28-e1f7-d675ae187b75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#モデル定義(入力次元)\n",
        "n_input = x_train.shape[1]\n",
        "n_output = len(list(set(y_train)))\n",
        "\n",
        "print(f'n_input: {n_input} n_output: {n_output}')"
      ],
      "metadata": {
        "id": "EHvGRPlMfHRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15630c88-b5a5-49af-a39b-caf1cb6b7f2c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_input: 2 n_output: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#モデル定義\n",
        "class Net(nn.Module):\n",
        "  def __init__(self, n_input, n_output):\n",
        "    super().__init__()\n",
        "    self.l1 = nn.Linear(n_input, n_output)\n",
        "\n",
        "    #書籍合わせ初期値１\n",
        "    self.l1.weight.data.fill_(1.0)\n",
        "    self.l1.bias.data.fill_(1.0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.l1(x)\n",
        "    return x1\n",
        "\n",
        "#インスタンスの生成\n",
        "net = Net(n_input, n_output)"
      ],
      "metadata": {
        "id": "u-BGEc71IKqd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#モデル確認\n",
        "for parameter in net.named_parameters():\n",
        "  print(parameter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzxqq0NsJAvt",
        "outputId": "8ce8e317-8dc8-49dc-f989-c31036e97887"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('l1.weight', Parameter containing:\n",
            "tensor([[1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]], requires_grad=True))\n",
            "('l1.bias', Parameter containing:\n",
            "tensor([1., 1., 1.], requires_grad=True))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#モデル概要表示\n",
        "print(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0KU8raMJKF2",
        "outputId": "cf557cb7-46b7-4e98-8bc0-1e8454bad968"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (l1): Linear(in_features=2, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#モデルのサマリー表示\n",
        "summary(net, (2,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QXA6biXJTlT",
        "outputId": "adbb0b72-cccf-4d71-901f-4c8fb6f0585a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "==========================================================================================\n",
              "Layer (type:depth-idx)                   Output Shape              Param #\n",
              "==========================================================================================\n",
              "Net                                      --                        --\n",
              "├─Linear: 1-1                            [3]                       9\n",
              "==========================================================================================\n",
              "Total params: 9\n",
              "Trainable params: 9\n",
              "Non-trainable params: 0\n",
              "Total mult-adds (M): 0.00\n",
              "==========================================================================================\n",
              "Input size (MB): 0.00\n",
              "Forward/backward pass size (MB): 0.00\n",
              "Params size (MB): 0.00\n",
              "Estimated Total Size (MB): 0.00\n",
              "=========================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#最適化アルゴリズムと損失関数\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.01\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "a9WMrRBBJZZA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#勾配降下法\n",
        "#データのテンソル化\n",
        "\n",
        "inputs = torch.tensor(x_train).float()\n",
        "labels = torch.tensor(y_train).long()\n",
        "\n",
        "inputs_test = torch.tensor(x_test).float()\n",
        "labels_test = torch.tensor(y_test).long()"
      ],
      "metadata": {
        "id": "oAGQwXYnJzoS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#計算グラフの可視化\n",
        "outputs = net(inputs)\n",
        "\n",
        "loss = criterion(outputs, labels)\n",
        "\n",
        "g = make_dot(loss, params=dict(net.named_parameters()))\n",
        "display(g)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "z7L0-OMJKe5o",
        "outputId": "82839286-fb05-4f29-83c3-9deb82841984"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7ff5c17af750>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"216pt\" height=\"391pt\"\n viewBox=\"0.00 0.00 216.00 391.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 387)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-387 212,-387 212,4 -4,4\"/>\n<!-- 140693494602448 -->\n<g id=\"node1\" class=\"node\">\n<title>140693494602448</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"130.5,-31 76.5,-31 76.5,0 130.5,0 130.5,-31\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-7\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> ()</text>\n</g>\n<!-- 140693496652560 -->\n<g id=\"node2\" class=\"node\">\n<title>140693496652560</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"160,-86 47,-86 47,-67 160,-67 160,-86\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-74\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">NllLossBackward0</text>\n</g>\n<!-- 140693496652560&#45;&gt;140693494602448 -->\n<g id=\"edge8\" class=\"edge\">\n<title>140693496652560&#45;&gt;140693494602448</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M103.5,-66.9688C103.5,-60.1289 103.5,-50.5621 103.5,-41.5298\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.0001,-41.3678 103.5,-31.3678 100.0001,-41.3678 107.0001,-41.3678\"/>\n</g>\n<!-- 140693740946640 -->\n<g id=\"node3\" class=\"node\">\n<title>140693740946640</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"169,-141 38,-141 38,-122 169,-122 169,-141\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-129\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">LogSoftmaxBackward0</text>\n</g>\n<!-- 140693740946640&#45;&gt;140693496652560 -->\n<g id=\"edge1\" class=\"edge\">\n<title>140693740946640&#45;&gt;140693496652560</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M103.5,-121.9197C103.5,-114.9083 103.5,-105.1442 103.5,-96.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.0001,-96.3408 103.5,-86.3408 100.0001,-96.3409 107.0001,-96.3408\"/>\n</g>\n<!-- 140693740949008 -->\n<g id=\"node4\" class=\"node\">\n<title>140693740949008</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"154,-196 53,-196 53,-177 154,-177 154,-196\"/>\n<text text-anchor=\"middle\" x=\"103.5\" y=\"-184\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AddmmBackward0</text>\n</g>\n<!-- 140693740949008&#45;&gt;140693740946640 -->\n<g id=\"edge2\" class=\"edge\">\n<title>140693740949008&#45;&gt;140693740946640</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M103.5,-176.9197C103.5,-169.9083 103.5,-160.1442 103.5,-151.4652\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"107.0001,-151.3408 103.5,-141.3408 100.0001,-151.3409 107.0001,-151.3408\"/>\n</g>\n<!-- 140693740908176 -->\n<g id=\"node5\" class=\"node\">\n<title>140693740908176</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"101,-251 0,-251 0,-232 101,-232 101,-251\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140693740908176&#45;&gt;140693740949008 -->\n<g id=\"edge3\" class=\"edge\">\n<title>140693740908176&#45;&gt;140693740949008</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M59.7319,-231.9197C67.2391,-224.1293 78.021,-212.9405 87.0049,-203.6176\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"89.5983,-205.9703 94.017,-196.3408 84.5578,-201.113 89.5983,-205.9703\"/>\n</g>\n<!-- 140693494481648 -->\n<g id=\"node6\" class=\"node\">\n<title>140693494481648</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"80,-317 21,-317 21,-287 80,-287 80,-317\"/>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-305\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">l1.bias</text>\n<text text-anchor=\"middle\" x=\"50.5\" y=\"-294\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (3)</text>\n</g>\n<!-- 140693494481648&#45;&gt;140693740908176 -->\n<g id=\"edge4\" class=\"edge\">\n<title>140693494481648&#45;&gt;140693740908176</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M50.5,-286.7333C50.5,-279.0322 50.5,-269.5977 50.5,-261.3414\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"54.0001,-261.0864 50.5,-251.0864 47.0001,-261.0864 54.0001,-261.0864\"/>\n</g>\n<!-- 140693740946000 -->\n<g id=\"node7\" class=\"node\">\n<title>140693740946000</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"196,-251 119,-251 119,-232 196,-232 196,-251\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-239\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">TBackward0</text>\n</g>\n<!-- 140693740946000&#45;&gt;140693740949008 -->\n<g id=\"edge5\" class=\"edge\">\n<title>140693740946000&#45;&gt;140693740949008</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M148.0939,-231.9197C140.4451,-224.1293 129.4597,-212.9405 120.3064,-203.6176\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"122.6653,-201.0244 113.1619,-196.3408 117.6704,-205.9286 122.6653,-201.0244\"/>\n</g>\n<!-- 140693740949072 -->\n<g id=\"node8\" class=\"node\">\n<title>140693740949072</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"208,-311.5 107,-311.5 107,-292.5 208,-292.5 208,-311.5\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-299.5\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">AccumulateGrad</text>\n</g>\n<!-- 140693740949072&#45;&gt;140693740946000 -->\n<g id=\"edge6\" class=\"edge\">\n<title>140693740949072&#45;&gt;140693740946000</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.5,-292.2796C157.5,-284.0376 157.5,-271.9457 157.5,-261.629\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"161.0001,-261.3972 157.5,-251.3972 154.0001,-261.3973 161.0001,-261.3972\"/>\n</g>\n<!-- 140693494482416 -->\n<g id=\"node9\" class=\"node\">\n<title>140693494482416</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"193,-383 122,-383 122,-353 193,-353 193,-383\"/>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-371\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\">l1.weight</text>\n<text text-anchor=\"middle\" x=\"157.5\" y=\"-360\" font-family=\"monospace\" font-size=\"10.00\" fill=\"#000000\"> (3, 2)</text>\n</g>\n<!-- 140693494482416&#45;&gt;140693740949072 -->\n<g id=\"edge7\" class=\"edge\">\n<title>140693494482416&#45;&gt;140693740949072</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.5,-352.6924C157.5,-343.5067 157.5,-331.7245 157.5,-321.8312\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"161.0001,-321.703 157.5,-311.7031 154.0001,-321.7031 161.0001,-321.703\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 予測ラベル値の取得方法\n",
        "# torch.max関数呼び出し\n",
        "# 2つめの引数は軸を意味している。1だと行ごとの集計。\n",
        "print(torch.max(outputs, 1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81_JEhvQK50Z",
        "outputId": "85d44b7f-451d-4d11-a9f5-b9a7d887f1be"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.return_types.max(\n",
            "values=tensor([12.0000, 12.7000,  7.6000, 13.0000, 12.3000,  7.6000,  7.3000, 11.1000,\n",
            "        12.1000, 13.3000,  8.0000,  7.0000, 10.3000,  7.6000, 11.7000, 13.3000,\n",
            "         7.4000, 13.5000,  8.2000,  8.4000, 12.7000,  6.6000,  7.9000, 12.2000,\n",
            "        14.6000, 12.0000, 10.2000, 10.5000,  7.1000,  7.3000, 12.6000, 12.7000,\n",
            "         7.4000,  7.7000, 10.8000, 11.5000, 11.5000, 14.0000, 12.8000, 10.8000,\n",
            "        10.8000, 15.2000,  7.5000,  7.8000, 11.1000, 13.6000, 12.9000, 14.2000,\n",
            "        12.7000,  7.6000, 10.9000,  7.0000, 10.9000, 11.2000,  7.4000, 11.7000,\n",
            "        13.3000, 11.5000, 13.4000, 12.7000,  7.7000, 11.8000,  7.0000, 12.6000,\n",
            "        11.7000, 10.9000,  9.2000, 12.2000, 10.4000, 12.1000,  7.5000,  9.1000,\n",
            "        11.1000, 12.0000, 14.3000], grad_fn=<MaxBackward0>),\n",
            "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0]))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.max(outputs, 1)[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xJxf8MoLwwx",
        "outputId": "b84ff8fb-cce0-4723-c695-e463957fbc49"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#繰り返し計算\n",
        "lr = 0.01\n",
        "\n",
        "#インスタンス初期化\n",
        "net = Net(n_input, n_output)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.SGD(net.parameters(), lr=lr)\n",
        "\n",
        "num_epochs = 10000\n",
        "\n",
        "#評価結果記録用\n",
        "history = np.zeros((0,5))"
      ],
      "metadata": {
        "id": "QYXdk8vpME7Z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#繰り返し計算メインループ\n",
        "for epoch in range(num_epochs):\n",
        "  #訓練フェーズ\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  outputs = net(inputs)\n",
        "\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  loss.backward()\n",
        "\n",
        "  optimizer.step()\n",
        "\n",
        "  predicted = torch.max(outputs, 1)[1]\n",
        "\n",
        "  train_loss = loss.item()\n",
        "  train_acc = (predicted == labels).sum() / len(labels)\n",
        "\n",
        "  #予測フェーズ\n",
        "  outputs_test = net(inputs_test)\n",
        "\n",
        "  loss_test = criterion(outputs_test, labels_test)\n",
        "\n",
        "  predicted_test = torch.max(outputs_test, 1)[1]\n",
        "\n",
        "  val_loss = loss_test.item()\n",
        "  val_acc = (predicted_test == labels_test).sum() / len(labels_test)\n",
        "\n",
        "  if ((epoch) % 10 == 0):\n",
        "    print(f'Epoch[{epoch}/{num_epochs}], loss: {train_loss:.5f}, acc: {train_acc:.5f} val_loss: {val_loss:.5f}')\n",
        "    item = np.array([epoch, train_loss, train_acc, val_loss, val_acc])\n",
        "    history = np.vstack((history, item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyP8eBSGNtE2",
        "outputId": "d686344a-3208-47d9-94fa-dc7db69f977c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[0/10000], loss: 1.09861, acc: 0.30667 val_loss: 1.09263\n",
            "Epoch[10/10000], loss: 1.03580, acc: 0.40000 val_loss: 1.06403\n",
            "Epoch[20/10000], loss: 1.00477, acc: 0.40000 val_loss: 1.03347\n",
            "Epoch[30/10000], loss: 0.97672, acc: 0.40000 val_loss: 1.00264\n",
            "Epoch[40/10000], loss: 0.95057, acc: 0.41333 val_loss: 0.97351\n",
            "Epoch[50/10000], loss: 0.92616, acc: 0.48000 val_loss: 0.94631\n",
            "Epoch[60/10000], loss: 0.90338, acc: 0.69333 val_loss: 0.92098\n",
            "Epoch[70/10000], loss: 0.88212, acc: 0.70667 val_loss: 0.89740\n",
            "Epoch[80/10000], loss: 0.86227, acc: 0.70667 val_loss: 0.87545\n",
            "Epoch[90/10000], loss: 0.84373, acc: 0.70667 val_loss: 0.85500\n",
            "Epoch[100/10000], loss: 0.82640, acc: 0.70667 val_loss: 0.83594\n",
            "Epoch[110/10000], loss: 0.81019, acc: 0.72000 val_loss: 0.81815\n",
            "Epoch[120/10000], loss: 0.79500, acc: 0.72000 val_loss: 0.80153\n",
            "Epoch[130/10000], loss: 0.78077, acc: 0.73333 val_loss: 0.78599\n",
            "Epoch[140/10000], loss: 0.76741, acc: 0.74667 val_loss: 0.77142\n",
            "Epoch[150/10000], loss: 0.75485, acc: 0.74667 val_loss: 0.75777\n",
            "Epoch[160/10000], loss: 0.74303, acc: 0.74667 val_loss: 0.74494\n",
            "Epoch[170/10000], loss: 0.73189, acc: 0.76000 val_loss: 0.73288\n",
            "Epoch[180/10000], loss: 0.72138, acc: 0.77333 val_loss: 0.72151\n",
            "Epoch[190/10000], loss: 0.71145, acc: 0.82667 val_loss: 0.71079\n",
            "Epoch[200/10000], loss: 0.70205, acc: 0.82667 val_loss: 0.70067\n",
            "Epoch[210/10000], loss: 0.69315, acc: 0.84000 val_loss: 0.69109\n",
            "Epoch[220/10000], loss: 0.68470, acc: 0.84000 val_loss: 0.68202\n",
            "Epoch[230/10000], loss: 0.67667, acc: 0.86667 val_loss: 0.67341\n",
            "Epoch[240/10000], loss: 0.66904, acc: 0.86667 val_loss: 0.66524\n",
            "Epoch[250/10000], loss: 0.66176, acc: 0.86667 val_loss: 0.65746\n",
            "Epoch[260/10000], loss: 0.65483, acc: 0.85333 val_loss: 0.65005\n",
            "Epoch[270/10000], loss: 0.64820, acc: 0.85333 val_loss: 0.64299\n",
            "Epoch[280/10000], loss: 0.64187, acc: 0.85333 val_loss: 0.63625\n",
            "Epoch[290/10000], loss: 0.63581, acc: 0.86667 val_loss: 0.62980\n",
            "Epoch[300/10000], loss: 0.63000, acc: 0.88000 val_loss: 0.62363\n",
            "Epoch[310/10000], loss: 0.62443, acc: 0.89333 val_loss: 0.61772\n",
            "Epoch[320/10000], loss: 0.61909, acc: 0.89333 val_loss: 0.61205\n",
            "Epoch[330/10000], loss: 0.61394, acc: 0.89333 val_loss: 0.60661\n",
            "Epoch[340/10000], loss: 0.60900, acc: 0.89333 val_loss: 0.60138\n",
            "Epoch[350/10000], loss: 0.60423, acc: 0.89333 val_loss: 0.59635\n",
            "Epoch[360/10000], loss: 0.59964, acc: 0.90667 val_loss: 0.59150\n",
            "Epoch[370/10000], loss: 0.59521, acc: 0.92000 val_loss: 0.58683\n",
            "Epoch[380/10000], loss: 0.59093, acc: 0.92000 val_loss: 0.58232\n",
            "Epoch[390/10000], loss: 0.58679, acc: 0.92000 val_loss: 0.57797\n",
            "Epoch[400/10000], loss: 0.58279, acc: 0.92000 val_loss: 0.57377\n",
            "Epoch[410/10000], loss: 0.57891, acc: 0.92000 val_loss: 0.56970\n",
            "Epoch[420/10000], loss: 0.57516, acc: 0.92000 val_loss: 0.56576\n",
            "Epoch[430/10000], loss: 0.57152, acc: 0.90667 val_loss: 0.56195\n",
            "Epoch[440/10000], loss: 0.56799, acc: 0.90667 val_loss: 0.55825\n",
            "Epoch[450/10000], loss: 0.56456, acc: 0.90667 val_loss: 0.55466\n",
            "Epoch[460/10000], loss: 0.56123, acc: 0.90667 val_loss: 0.55118\n",
            "Epoch[470/10000], loss: 0.55799, acc: 0.90667 val_loss: 0.54779\n",
            "Epoch[480/10000], loss: 0.55484, acc: 0.90667 val_loss: 0.54451\n",
            "Epoch[490/10000], loss: 0.55177, acc: 0.90667 val_loss: 0.54131\n",
            "Epoch[500/10000], loss: 0.54878, acc: 0.90667 val_loss: 0.53819\n",
            "Epoch[510/10000], loss: 0.54587, acc: 0.90667 val_loss: 0.53516\n",
            "Epoch[520/10000], loss: 0.54303, acc: 0.90667 val_loss: 0.53221\n",
            "Epoch[530/10000], loss: 0.54026, acc: 0.90667 val_loss: 0.52933\n",
            "Epoch[540/10000], loss: 0.53755, acc: 0.90667 val_loss: 0.52652\n",
            "Epoch[550/10000], loss: 0.53491, acc: 0.90667 val_loss: 0.52377\n",
            "Epoch[560/10000], loss: 0.53233, acc: 0.90667 val_loss: 0.52110\n",
            "Epoch[570/10000], loss: 0.52981, acc: 0.90667 val_loss: 0.51848\n",
            "Epoch[580/10000], loss: 0.52734, acc: 0.90667 val_loss: 0.51592\n",
            "Epoch[590/10000], loss: 0.52493, acc: 0.90667 val_loss: 0.51342\n",
            "Epoch[600/10000], loss: 0.52256, acc: 0.90667 val_loss: 0.51098\n",
            "Epoch[610/10000], loss: 0.52025, acc: 0.90667 val_loss: 0.50859\n",
            "Epoch[620/10000], loss: 0.51798, acc: 0.90667 val_loss: 0.50624\n",
            "Epoch[630/10000], loss: 0.51576, acc: 0.90667 val_loss: 0.50395\n",
            "Epoch[640/10000], loss: 0.51358, acc: 0.90667 val_loss: 0.50170\n",
            "Epoch[650/10000], loss: 0.51144, acc: 0.90667 val_loss: 0.49949\n",
            "Epoch[660/10000], loss: 0.50934, acc: 0.90667 val_loss: 0.49733\n",
            "Epoch[670/10000], loss: 0.50728, acc: 0.90667 val_loss: 0.49521\n",
            "Epoch[680/10000], loss: 0.50526, acc: 0.90667 val_loss: 0.49313\n",
            "Epoch[690/10000], loss: 0.50328, acc: 0.90667 val_loss: 0.49109\n",
            "Epoch[700/10000], loss: 0.50133, acc: 0.90667 val_loss: 0.48908\n",
            "Epoch[710/10000], loss: 0.49941, acc: 0.90667 val_loss: 0.48711\n",
            "Epoch[720/10000], loss: 0.49752, acc: 0.90667 val_loss: 0.48517\n",
            "Epoch[730/10000], loss: 0.49567, acc: 0.90667 val_loss: 0.48327\n",
            "Epoch[740/10000], loss: 0.49385, acc: 0.90667 val_loss: 0.48140\n",
            "Epoch[750/10000], loss: 0.49205, acc: 0.90667 val_loss: 0.47956\n",
            "Epoch[760/10000], loss: 0.49029, acc: 0.90667 val_loss: 0.47775\n",
            "Epoch[770/10000], loss: 0.48855, acc: 0.90667 val_loss: 0.47597\n",
            "Epoch[780/10000], loss: 0.48684, acc: 0.90667 val_loss: 0.47422\n",
            "Epoch[790/10000], loss: 0.48515, acc: 0.89333 val_loss: 0.47249\n",
            "Epoch[800/10000], loss: 0.48349, acc: 0.89333 val_loss: 0.47079\n",
            "Epoch[810/10000], loss: 0.48186, acc: 0.89333 val_loss: 0.46912\n",
            "Epoch[820/10000], loss: 0.48024, acc: 0.89333 val_loss: 0.46747\n",
            "Epoch[830/10000], loss: 0.47865, acc: 0.89333 val_loss: 0.46585\n",
            "Epoch[840/10000], loss: 0.47709, acc: 0.89333 val_loss: 0.46425\n",
            "Epoch[850/10000], loss: 0.47554, acc: 0.89333 val_loss: 0.46267\n",
            "Epoch[860/10000], loss: 0.47402, acc: 0.89333 val_loss: 0.46111\n",
            "Epoch[870/10000], loss: 0.47251, acc: 0.89333 val_loss: 0.45958\n",
            "Epoch[880/10000], loss: 0.47103, acc: 0.89333 val_loss: 0.45806\n",
            "Epoch[890/10000], loss: 0.46956, acc: 0.89333 val_loss: 0.45657\n",
            "Epoch[900/10000], loss: 0.46811, acc: 0.89333 val_loss: 0.45509\n",
            "Epoch[910/10000], loss: 0.46668, acc: 0.89333 val_loss: 0.45364\n",
            "Epoch[920/10000], loss: 0.46527, acc: 0.89333 val_loss: 0.45220\n",
            "Epoch[930/10000], loss: 0.46388, acc: 0.89333 val_loss: 0.45078\n",
            "Epoch[940/10000], loss: 0.46250, acc: 0.89333 val_loss: 0.44938\n",
            "Epoch[950/10000], loss: 0.46114, acc: 0.89333 val_loss: 0.44800\n",
            "Epoch[960/10000], loss: 0.45980, acc: 0.89333 val_loss: 0.44663\n",
            "Epoch[970/10000], loss: 0.45847, acc: 0.89333 val_loss: 0.44528\n",
            "Epoch[980/10000], loss: 0.45716, acc: 0.89333 val_loss: 0.44395\n",
            "Epoch[990/10000], loss: 0.45586, acc: 0.89333 val_loss: 0.44263\n",
            "Epoch[1000/10000], loss: 0.45458, acc: 0.89333 val_loss: 0.44133\n",
            "Epoch[1010/10000], loss: 0.45331, acc: 0.89333 val_loss: 0.44004\n",
            "Epoch[1020/10000], loss: 0.45205, acc: 0.89333 val_loss: 0.43877\n",
            "Epoch[1030/10000], loss: 0.45081, acc: 0.89333 val_loss: 0.43751\n",
            "Epoch[1040/10000], loss: 0.44958, acc: 0.89333 val_loss: 0.43626\n",
            "Epoch[1050/10000], loss: 0.44836, acc: 0.89333 val_loss: 0.43503\n",
            "Epoch[1060/10000], loss: 0.44716, acc: 0.89333 val_loss: 0.43381\n",
            "Epoch[1070/10000], loss: 0.44597, acc: 0.89333 val_loss: 0.43260\n",
            "Epoch[1080/10000], loss: 0.44479, acc: 0.89333 val_loss: 0.43141\n",
            "Epoch[1090/10000], loss: 0.44363, acc: 0.89333 val_loss: 0.43023\n",
            "Epoch[1100/10000], loss: 0.44247, acc: 0.89333 val_loss: 0.42906\n",
            "Epoch[1110/10000], loss: 0.44133, acc: 0.89333 val_loss: 0.42790\n",
            "Epoch[1120/10000], loss: 0.44020, acc: 0.89333 val_loss: 0.42676\n",
            "Epoch[1130/10000], loss: 0.43908, acc: 0.89333 val_loss: 0.42562\n",
            "Epoch[1140/10000], loss: 0.43797, acc: 0.89333 val_loss: 0.42450\n",
            "Epoch[1150/10000], loss: 0.43687, acc: 0.89333 val_loss: 0.42339\n",
            "Epoch[1160/10000], loss: 0.43578, acc: 0.89333 val_loss: 0.42229\n",
            "Epoch[1170/10000], loss: 0.43470, acc: 0.89333 val_loss: 0.42120\n",
            "Epoch[1180/10000], loss: 0.43363, acc: 0.89333 val_loss: 0.42012\n",
            "Epoch[1190/10000], loss: 0.43257, acc: 0.89333 val_loss: 0.41905\n",
            "Epoch[1200/10000], loss: 0.43152, acc: 0.89333 val_loss: 0.41799\n",
            "Epoch[1210/10000], loss: 0.43048, acc: 0.89333 val_loss: 0.41694\n",
            "Epoch[1220/10000], loss: 0.42945, acc: 0.89333 val_loss: 0.41590\n",
            "Epoch[1230/10000], loss: 0.42843, acc: 0.89333 val_loss: 0.41487\n",
            "Epoch[1240/10000], loss: 0.42742, acc: 0.89333 val_loss: 0.41384\n",
            "Epoch[1250/10000], loss: 0.42641, acc: 0.89333 val_loss: 0.41283\n",
            "Epoch[1260/10000], loss: 0.42542, acc: 0.89333 val_loss: 0.41182\n",
            "Epoch[1270/10000], loss: 0.42443, acc: 0.89333 val_loss: 0.41083\n",
            "Epoch[1280/10000], loss: 0.42345, acc: 0.89333 val_loss: 0.40984\n",
            "Epoch[1290/10000], loss: 0.42248, acc: 0.89333 val_loss: 0.40886\n",
            "Epoch[1300/10000], loss: 0.42152, acc: 0.89333 val_loss: 0.40789\n",
            "Epoch[1310/10000], loss: 0.42056, acc: 0.89333 val_loss: 0.40693\n",
            "Epoch[1320/10000], loss: 0.41962, acc: 0.89333 val_loss: 0.40598\n",
            "Epoch[1330/10000], loss: 0.41868, acc: 0.89333 val_loss: 0.40503\n",
            "Epoch[1340/10000], loss: 0.41775, acc: 0.89333 val_loss: 0.40409\n",
            "Epoch[1350/10000], loss: 0.41682, acc: 0.89333 val_loss: 0.40316\n",
            "Epoch[1360/10000], loss: 0.41590, acc: 0.89333 val_loss: 0.40224\n",
            "Epoch[1370/10000], loss: 0.41499, acc: 0.89333 val_loss: 0.40132\n",
            "Epoch[1380/10000], loss: 0.41409, acc: 0.89333 val_loss: 0.40041\n",
            "Epoch[1390/10000], loss: 0.41320, acc: 0.89333 val_loss: 0.39951\n",
            "Epoch[1400/10000], loss: 0.41231, acc: 0.89333 val_loss: 0.39861\n",
            "Epoch[1410/10000], loss: 0.41143, acc: 0.89333 val_loss: 0.39773\n",
            "Epoch[1420/10000], loss: 0.41055, acc: 0.89333 val_loss: 0.39685\n",
            "Epoch[1430/10000], loss: 0.40968, acc: 0.89333 val_loss: 0.39597\n",
            "Epoch[1440/10000], loss: 0.40882, acc: 0.89333 val_loss: 0.39510\n",
            "Epoch[1450/10000], loss: 0.40796, acc: 0.89333 val_loss: 0.39424\n",
            "Epoch[1460/10000], loss: 0.40711, acc: 0.89333 val_loss: 0.39339\n",
            "Epoch[1470/10000], loss: 0.40627, acc: 0.89333 val_loss: 0.39254\n",
            "Epoch[1480/10000], loss: 0.40543, acc: 0.90667 val_loss: 0.39170\n",
            "Epoch[1490/10000], loss: 0.40460, acc: 0.90667 val_loss: 0.39086\n",
            "Epoch[1500/10000], loss: 0.40378, acc: 0.90667 val_loss: 0.39003\n",
            "Epoch[1510/10000], loss: 0.40296, acc: 0.90667 val_loss: 0.38921\n",
            "Epoch[1520/10000], loss: 0.40214, acc: 0.90667 val_loss: 0.38839\n",
            "Epoch[1530/10000], loss: 0.40134, acc: 0.90667 val_loss: 0.38758\n",
            "Epoch[1540/10000], loss: 0.40053, acc: 0.90667 val_loss: 0.38677\n",
            "Epoch[1550/10000], loss: 0.39974, acc: 0.90667 val_loss: 0.38597\n",
            "Epoch[1560/10000], loss: 0.39894, acc: 0.90667 val_loss: 0.38517\n",
            "Epoch[1570/10000], loss: 0.39816, acc: 0.90667 val_loss: 0.38438\n",
            "Epoch[1580/10000], loss: 0.39738, acc: 0.90667 val_loss: 0.38360\n",
            "Epoch[1590/10000], loss: 0.39660, acc: 0.90667 val_loss: 0.38282\n",
            "Epoch[1600/10000], loss: 0.39583, acc: 0.90667 val_loss: 0.38204\n",
            "Epoch[1610/10000], loss: 0.39507, acc: 0.90667 val_loss: 0.38128\n",
            "Epoch[1620/10000], loss: 0.39431, acc: 0.90667 val_loss: 0.38051\n",
            "Epoch[1630/10000], loss: 0.39355, acc: 0.90667 val_loss: 0.37975\n",
            "Epoch[1640/10000], loss: 0.39280, acc: 0.90667 val_loss: 0.37900\n",
            "Epoch[1650/10000], loss: 0.39206, acc: 0.90667 val_loss: 0.37825\n",
            "Epoch[1660/10000], loss: 0.39132, acc: 0.90667 val_loss: 0.37751\n",
            "Epoch[1670/10000], loss: 0.39058, acc: 0.90667 val_loss: 0.37677\n",
            "Epoch[1680/10000], loss: 0.38985, acc: 0.90667 val_loss: 0.37604\n",
            "Epoch[1690/10000], loss: 0.38913, acc: 0.90667 val_loss: 0.37531\n",
            "Epoch[1700/10000], loss: 0.38841, acc: 0.90667 val_loss: 0.37458\n",
            "Epoch[1710/10000], loss: 0.38769, acc: 0.90667 val_loss: 0.37386\n",
            "Epoch[1720/10000], loss: 0.38698, acc: 0.90667 val_loss: 0.37315\n",
            "Epoch[1730/10000], loss: 0.38627, acc: 0.90667 val_loss: 0.37244\n",
            "Epoch[1740/10000], loss: 0.38557, acc: 0.90667 val_loss: 0.37173\n",
            "Epoch[1750/10000], loss: 0.38487, acc: 0.90667 val_loss: 0.37103\n",
            "Epoch[1760/10000], loss: 0.38417, acc: 0.90667 val_loss: 0.37033\n",
            "Epoch[1770/10000], loss: 0.38348, acc: 0.90667 val_loss: 0.36964\n",
            "Epoch[1780/10000], loss: 0.38280, acc: 0.90667 val_loss: 0.36895\n",
            "Epoch[1790/10000], loss: 0.38212, acc: 0.90667 val_loss: 0.36826\n",
            "Epoch[1800/10000], loss: 0.38144, acc: 0.90667 val_loss: 0.36758\n",
            "Epoch[1810/10000], loss: 0.38076, acc: 0.90667 val_loss: 0.36690\n",
            "Epoch[1820/10000], loss: 0.38009, acc: 0.90667 val_loss: 0.36623\n",
            "Epoch[1830/10000], loss: 0.37943, acc: 0.90667 val_loss: 0.36556\n",
            "Epoch[1840/10000], loss: 0.37877, acc: 0.90667 val_loss: 0.36490\n",
            "Epoch[1850/10000], loss: 0.37811, acc: 0.90667 val_loss: 0.36424\n",
            "Epoch[1860/10000], loss: 0.37746, acc: 0.90667 val_loss: 0.36358\n",
            "Epoch[1870/10000], loss: 0.37681, acc: 0.90667 val_loss: 0.36293\n",
            "Epoch[1880/10000], loss: 0.37616, acc: 0.90667 val_loss: 0.36228\n",
            "Epoch[1890/10000], loss: 0.37552, acc: 0.90667 val_loss: 0.36163\n",
            "Epoch[1900/10000], loss: 0.37488, acc: 0.90667 val_loss: 0.36099\n",
            "Epoch[1910/10000], loss: 0.37424, acc: 0.90667 val_loss: 0.36035\n",
            "Epoch[1920/10000], loss: 0.37361, acc: 0.90667 val_loss: 0.35972\n",
            "Epoch[1930/10000], loss: 0.37298, acc: 0.90667 val_loss: 0.35909\n",
            "Epoch[1940/10000], loss: 0.37236, acc: 0.90667 val_loss: 0.35846\n",
            "Epoch[1950/10000], loss: 0.37174, acc: 0.90667 val_loss: 0.35784\n",
            "Epoch[1960/10000], loss: 0.37112, acc: 0.90667 val_loss: 0.35722\n",
            "Epoch[1970/10000], loss: 0.37051, acc: 0.90667 val_loss: 0.35660\n",
            "Epoch[1980/10000], loss: 0.36990, acc: 0.90667 val_loss: 0.35599\n",
            "Epoch[1990/10000], loss: 0.36929, acc: 0.90667 val_loss: 0.35538\n",
            "Epoch[2000/10000], loss: 0.36869, acc: 0.90667 val_loss: 0.35477\n",
            "Epoch[2010/10000], loss: 0.36809, acc: 0.90667 val_loss: 0.35417\n",
            "Epoch[2020/10000], loss: 0.36749, acc: 0.90667 val_loss: 0.35357\n",
            "Epoch[2030/10000], loss: 0.36690, acc: 0.90667 val_loss: 0.35298\n",
            "Epoch[2040/10000], loss: 0.36631, acc: 0.90667 val_loss: 0.35238\n",
            "Epoch[2050/10000], loss: 0.36572, acc: 0.90667 val_loss: 0.35179\n",
            "Epoch[2060/10000], loss: 0.36514, acc: 0.90667 val_loss: 0.35121\n",
            "Epoch[2070/10000], loss: 0.36455, acc: 0.90667 val_loss: 0.35062\n",
            "Epoch[2080/10000], loss: 0.36398, acc: 0.90667 val_loss: 0.35004\n",
            "Epoch[2090/10000], loss: 0.36340, acc: 0.90667 val_loss: 0.34947\n",
            "Epoch[2100/10000], loss: 0.36283, acc: 0.90667 val_loss: 0.34889\n",
            "Epoch[2110/10000], loss: 0.36226, acc: 0.90667 val_loss: 0.34832\n",
            "Epoch[2120/10000], loss: 0.36170, acc: 0.90667 val_loss: 0.34775\n",
            "Epoch[2130/10000], loss: 0.36114, acc: 0.90667 val_loss: 0.34719\n",
            "Epoch[2140/10000], loss: 0.36058, acc: 0.90667 val_loss: 0.34663\n",
            "Epoch[2150/10000], loss: 0.36002, acc: 0.90667 val_loss: 0.34607\n",
            "Epoch[2160/10000], loss: 0.35947, acc: 0.90667 val_loss: 0.34551\n",
            "Epoch[2170/10000], loss: 0.35892, acc: 0.90667 val_loss: 0.34496\n",
            "Epoch[2180/10000], loss: 0.35837, acc: 0.90667 val_loss: 0.34441\n",
            "Epoch[2190/10000], loss: 0.35782, acc: 0.90667 val_loss: 0.34386\n",
            "Epoch[2200/10000], loss: 0.35728, acc: 0.90667 val_loss: 0.34331\n",
            "Epoch[2210/10000], loss: 0.35674, acc: 0.90667 val_loss: 0.34277\n",
            "Epoch[2220/10000], loss: 0.35621, acc: 0.90667 val_loss: 0.34223\n",
            "Epoch[2230/10000], loss: 0.35567, acc: 0.90667 val_loss: 0.34170\n",
            "Epoch[2240/10000], loss: 0.35514, acc: 0.90667 val_loss: 0.34116\n",
            "Epoch[2250/10000], loss: 0.35461, acc: 0.90667 val_loss: 0.34063\n",
            "Epoch[2260/10000], loss: 0.35409, acc: 0.90667 val_loss: 0.34010\n",
            "Epoch[2270/10000], loss: 0.35356, acc: 0.90667 val_loss: 0.33958\n",
            "Epoch[2280/10000], loss: 0.35304, acc: 0.90667 val_loss: 0.33905\n",
            "Epoch[2290/10000], loss: 0.35253, acc: 0.90667 val_loss: 0.33853\n",
            "Epoch[2300/10000], loss: 0.35201, acc: 0.90667 val_loss: 0.33802\n",
            "Epoch[2310/10000], loss: 0.35150, acc: 0.90667 val_loss: 0.33750\n",
            "Epoch[2320/10000], loss: 0.35099, acc: 0.90667 val_loss: 0.33699\n",
            "Epoch[2330/10000], loss: 0.35048, acc: 0.90667 val_loss: 0.33648\n",
            "Epoch[2340/10000], loss: 0.34998, acc: 0.90667 val_loss: 0.33597\n",
            "Epoch[2350/10000], loss: 0.34947, acc: 0.90667 val_loss: 0.33546\n",
            "Epoch[2360/10000], loss: 0.34897, acc: 0.90667 val_loss: 0.33496\n",
            "Epoch[2370/10000], loss: 0.34848, acc: 0.90667 val_loss: 0.33446\n",
            "Epoch[2380/10000], loss: 0.34798, acc: 0.90667 val_loss: 0.33396\n",
            "Epoch[2390/10000], loss: 0.34749, acc: 0.90667 val_loss: 0.33347\n",
            "Epoch[2400/10000], loss: 0.34700, acc: 0.90667 val_loss: 0.33297\n",
            "Epoch[2410/10000], loss: 0.34651, acc: 0.90667 val_loss: 0.33248\n",
            "Epoch[2420/10000], loss: 0.34602, acc: 0.90667 val_loss: 0.33199\n",
            "Epoch[2430/10000], loss: 0.34554, acc: 0.90667 val_loss: 0.33151\n",
            "Epoch[2440/10000], loss: 0.34506, acc: 0.90667 val_loss: 0.33102\n",
            "Epoch[2450/10000], loss: 0.34458, acc: 0.90667 val_loss: 0.33054\n",
            "Epoch[2460/10000], loss: 0.34411, acc: 0.90667 val_loss: 0.33006\n",
            "Epoch[2470/10000], loss: 0.34363, acc: 0.90667 val_loss: 0.32959\n",
            "Epoch[2480/10000], loss: 0.34316, acc: 0.90667 val_loss: 0.32911\n",
            "Epoch[2490/10000], loss: 0.34269, acc: 0.90667 val_loss: 0.32864\n",
            "Epoch[2500/10000], loss: 0.34222, acc: 0.90667 val_loss: 0.32817\n",
            "Epoch[2510/10000], loss: 0.34176, acc: 0.90667 val_loss: 0.32770\n",
            "Epoch[2520/10000], loss: 0.34130, acc: 0.90667 val_loss: 0.32723\n",
            "Epoch[2530/10000], loss: 0.34083, acc: 0.90667 val_loss: 0.32677\n",
            "Epoch[2540/10000], loss: 0.34038, acc: 0.90667 val_loss: 0.32631\n",
            "Epoch[2550/10000], loss: 0.33992, acc: 0.90667 val_loss: 0.32585\n",
            "Epoch[2560/10000], loss: 0.33947, acc: 0.90667 val_loss: 0.32539\n",
            "Epoch[2570/10000], loss: 0.33901, acc: 0.90667 val_loss: 0.32493\n",
            "Epoch[2580/10000], loss: 0.33856, acc: 0.90667 val_loss: 0.32448\n",
            "Epoch[2590/10000], loss: 0.33812, acc: 0.90667 val_loss: 0.32403\n",
            "Epoch[2600/10000], loss: 0.33767, acc: 0.90667 val_loss: 0.32358\n",
            "Epoch[2610/10000], loss: 0.33723, acc: 0.90667 val_loss: 0.32313\n",
            "Epoch[2620/10000], loss: 0.33678, acc: 0.90667 val_loss: 0.32269\n",
            "Epoch[2630/10000], loss: 0.33634, acc: 0.90667 val_loss: 0.32225\n",
            "Epoch[2640/10000], loss: 0.33591, acc: 0.90667 val_loss: 0.32180\n",
            "Epoch[2650/10000], loss: 0.33547, acc: 0.90667 val_loss: 0.32136\n",
            "Epoch[2660/10000], loss: 0.33504, acc: 0.90667 val_loss: 0.32093\n",
            "Epoch[2670/10000], loss: 0.33460, acc: 0.90667 val_loss: 0.32049\n",
            "Epoch[2680/10000], loss: 0.33417, acc: 0.90667 val_loss: 0.32006\n",
            "Epoch[2690/10000], loss: 0.33375, acc: 0.90667 val_loss: 0.31963\n",
            "Epoch[2700/10000], loss: 0.33332, acc: 0.90667 val_loss: 0.31920\n",
            "Epoch[2710/10000], loss: 0.33290, acc: 0.90667 val_loss: 0.31877\n",
            "Epoch[2720/10000], loss: 0.33247, acc: 0.90667 val_loss: 0.31834\n",
            "Epoch[2730/10000], loss: 0.33205, acc: 0.90667 val_loss: 0.31792\n",
            "Epoch[2740/10000], loss: 0.33164, acc: 0.90667 val_loss: 0.31750\n",
            "Epoch[2750/10000], loss: 0.33122, acc: 0.90667 val_loss: 0.31708\n",
            "Epoch[2760/10000], loss: 0.33080, acc: 0.90667 val_loss: 0.31666\n",
            "Epoch[2770/10000], loss: 0.33039, acc: 0.90667 val_loss: 0.31624\n",
            "Epoch[2780/10000], loss: 0.32998, acc: 0.90667 val_loss: 0.31583\n",
            "Epoch[2790/10000], loss: 0.32957, acc: 0.90667 val_loss: 0.31542\n",
            "Epoch[2800/10000], loss: 0.32916, acc: 0.90667 val_loss: 0.31500\n",
            "Epoch[2810/10000], loss: 0.32876, acc: 0.90667 val_loss: 0.31460\n",
            "Epoch[2820/10000], loss: 0.32835, acc: 0.90667 val_loss: 0.31419\n",
            "Epoch[2830/10000], loss: 0.32795, acc: 0.90667 val_loss: 0.31378\n",
            "Epoch[2840/10000], loss: 0.32755, acc: 0.90667 val_loss: 0.31338\n",
            "Epoch[2850/10000], loss: 0.32715, acc: 0.90667 val_loss: 0.31297\n",
            "Epoch[2860/10000], loss: 0.32675, acc: 0.90667 val_loss: 0.31257\n",
            "Epoch[2870/10000], loss: 0.32636, acc: 0.90667 val_loss: 0.31217\n",
            "Epoch[2880/10000], loss: 0.32597, acc: 0.90667 val_loss: 0.31178\n",
            "Epoch[2890/10000], loss: 0.32557, acc: 0.90667 val_loss: 0.31138\n",
            "Epoch[2900/10000], loss: 0.32518, acc: 0.90667 val_loss: 0.31099\n",
            "Epoch[2910/10000], loss: 0.32480, acc: 0.90667 val_loss: 0.31060\n",
            "Epoch[2920/10000], loss: 0.32441, acc: 0.90667 val_loss: 0.31020\n",
            "Epoch[2930/10000], loss: 0.32402, acc: 0.90667 val_loss: 0.30982\n",
            "Epoch[2940/10000], loss: 0.32364, acc: 0.90667 val_loss: 0.30943\n",
            "Epoch[2950/10000], loss: 0.32326, acc: 0.90667 val_loss: 0.30904\n",
            "Epoch[2960/10000], loss: 0.32288, acc: 0.90667 val_loss: 0.30866\n",
            "Epoch[2970/10000], loss: 0.32250, acc: 0.90667 val_loss: 0.30827\n",
            "Epoch[2980/10000], loss: 0.32212, acc: 0.90667 val_loss: 0.30789\n",
            "Epoch[2990/10000], loss: 0.32175, acc: 0.90667 val_loss: 0.30751\n",
            "Epoch[3000/10000], loss: 0.32137, acc: 0.90667 val_loss: 0.30714\n",
            "Epoch[3010/10000], loss: 0.32100, acc: 0.90667 val_loss: 0.30676\n",
            "Epoch[3020/10000], loss: 0.32063, acc: 0.90667 val_loss: 0.30638\n",
            "Epoch[3030/10000], loss: 0.32026, acc: 0.90667 val_loss: 0.30601\n",
            "Epoch[3040/10000], loss: 0.31989, acc: 0.90667 val_loss: 0.30564\n",
            "Epoch[3050/10000], loss: 0.31952, acc: 0.90667 val_loss: 0.30527\n",
            "Epoch[3060/10000], loss: 0.31916, acc: 0.90667 val_loss: 0.30490\n",
            "Epoch[3070/10000], loss: 0.31880, acc: 0.90667 val_loss: 0.30453\n",
            "Epoch[3080/10000], loss: 0.31844, acc: 0.90667 val_loss: 0.30417\n",
            "Epoch[3090/10000], loss: 0.31807, acc: 0.90667 val_loss: 0.30380\n",
            "Epoch[3100/10000], loss: 0.31772, acc: 0.90667 val_loss: 0.30344\n",
            "Epoch[3110/10000], loss: 0.31736, acc: 0.90667 val_loss: 0.30308\n",
            "Epoch[3120/10000], loss: 0.31700, acc: 0.90667 val_loss: 0.30272\n",
            "Epoch[3130/10000], loss: 0.31665, acc: 0.90667 val_loss: 0.30236\n",
            "Epoch[3140/10000], loss: 0.31630, acc: 0.90667 val_loss: 0.30200\n",
            "Epoch[3150/10000], loss: 0.31594, acc: 0.90667 val_loss: 0.30165\n",
            "Epoch[3160/10000], loss: 0.31559, acc: 0.90667 val_loss: 0.30129\n",
            "Epoch[3170/10000], loss: 0.31525, acc: 0.90667 val_loss: 0.30094\n",
            "Epoch[3180/10000], loss: 0.31490, acc: 0.90667 val_loss: 0.30059\n",
            "Epoch[3190/10000], loss: 0.31455, acc: 0.90667 val_loss: 0.30024\n",
            "Epoch[3200/10000], loss: 0.31421, acc: 0.90667 val_loss: 0.29989\n",
            "Epoch[3210/10000], loss: 0.31386, acc: 0.90667 val_loss: 0.29954\n",
            "Epoch[3220/10000], loss: 0.31352, acc: 0.90667 val_loss: 0.29919\n",
            "Epoch[3230/10000], loss: 0.31318, acc: 0.90667 val_loss: 0.29885\n",
            "Epoch[3240/10000], loss: 0.31284, acc: 0.90667 val_loss: 0.29851\n",
            "Epoch[3250/10000], loss: 0.31251, acc: 0.90667 val_loss: 0.29816\n",
            "Epoch[3260/10000], loss: 0.31217, acc: 0.90667 val_loss: 0.29782\n",
            "Epoch[3270/10000], loss: 0.31183, acc: 0.90667 val_loss: 0.29748\n",
            "Epoch[3280/10000], loss: 0.31150, acc: 0.90667 val_loss: 0.29715\n",
            "Epoch[3290/10000], loss: 0.31117, acc: 0.90667 val_loss: 0.29681\n",
            "Epoch[3300/10000], loss: 0.31084, acc: 0.90667 val_loss: 0.29647\n",
            "Epoch[3310/10000], loss: 0.31051, acc: 0.90667 val_loss: 0.29614\n",
            "Epoch[3320/10000], loss: 0.31018, acc: 0.90667 val_loss: 0.29581\n",
            "Epoch[3330/10000], loss: 0.30985, acc: 0.90667 val_loss: 0.29548\n",
            "Epoch[3340/10000], loss: 0.30953, acc: 0.90667 val_loss: 0.29515\n",
            "Epoch[3350/10000], loss: 0.30920, acc: 0.90667 val_loss: 0.29482\n",
            "Epoch[3360/10000], loss: 0.30888, acc: 0.90667 val_loss: 0.29449\n",
            "Epoch[3370/10000], loss: 0.30856, acc: 0.90667 val_loss: 0.29416\n",
            "Epoch[3380/10000], loss: 0.30824, acc: 0.90667 val_loss: 0.29384\n",
            "Epoch[3390/10000], loss: 0.30792, acc: 0.90667 val_loss: 0.29351\n",
            "Epoch[3400/10000], loss: 0.30760, acc: 0.90667 val_loss: 0.29319\n",
            "Epoch[3410/10000], loss: 0.30728, acc: 0.90667 val_loss: 0.29287\n",
            "Epoch[3420/10000], loss: 0.30696, acc: 0.90667 val_loss: 0.29255\n",
            "Epoch[3430/10000], loss: 0.30665, acc: 0.90667 val_loss: 0.29223\n",
            "Epoch[3440/10000], loss: 0.30634, acc: 0.90667 val_loss: 0.29191\n",
            "Epoch[3450/10000], loss: 0.30602, acc: 0.90667 val_loss: 0.29159\n",
            "Epoch[3460/10000], loss: 0.30571, acc: 0.90667 val_loss: 0.29128\n",
            "Epoch[3470/10000], loss: 0.30540, acc: 0.90667 val_loss: 0.29096\n",
            "Epoch[3480/10000], loss: 0.30509, acc: 0.90667 val_loss: 0.29065\n",
            "Epoch[3490/10000], loss: 0.30479, acc: 0.90667 val_loss: 0.29034\n",
            "Epoch[3500/10000], loss: 0.30448, acc: 0.90667 val_loss: 0.29003\n",
            "Epoch[3510/10000], loss: 0.30417, acc: 0.90667 val_loss: 0.28972\n",
            "Epoch[3520/10000], loss: 0.30387, acc: 0.90667 val_loss: 0.28941\n",
            "Epoch[3530/10000], loss: 0.30357, acc: 0.90667 val_loss: 0.28910\n",
            "Epoch[3540/10000], loss: 0.30327, acc: 0.90667 val_loss: 0.28879\n",
            "Epoch[3550/10000], loss: 0.30297, acc: 0.90667 val_loss: 0.28849\n",
            "Epoch[3560/10000], loss: 0.30267, acc: 0.90667 val_loss: 0.28818\n",
            "Epoch[3570/10000], loss: 0.30237, acc: 0.90667 val_loss: 0.28788\n",
            "Epoch[3580/10000], loss: 0.30207, acc: 0.90667 val_loss: 0.28758\n",
            "Epoch[3590/10000], loss: 0.30177, acc: 0.90667 val_loss: 0.28728\n",
            "Epoch[3600/10000], loss: 0.30148, acc: 0.90667 val_loss: 0.28698\n",
            "Epoch[3610/10000], loss: 0.30119, acc: 0.90667 val_loss: 0.28668\n",
            "Epoch[3620/10000], loss: 0.30089, acc: 0.90667 val_loss: 0.28638\n",
            "Epoch[3630/10000], loss: 0.30060, acc: 0.90667 val_loss: 0.28608\n",
            "Epoch[3640/10000], loss: 0.30031, acc: 0.90667 val_loss: 0.28579\n",
            "Epoch[3650/10000], loss: 0.30002, acc: 0.90667 val_loss: 0.28549\n",
            "Epoch[3660/10000], loss: 0.29973, acc: 0.90667 val_loss: 0.28520\n",
            "Epoch[3670/10000], loss: 0.29944, acc: 0.90667 val_loss: 0.28491\n",
            "Epoch[3680/10000], loss: 0.29916, acc: 0.90667 val_loss: 0.28462\n",
            "Epoch[3690/10000], loss: 0.29887, acc: 0.90667 val_loss: 0.28433\n",
            "Epoch[3700/10000], loss: 0.29859, acc: 0.90667 val_loss: 0.28404\n",
            "Epoch[3710/10000], loss: 0.29830, acc: 0.90667 val_loss: 0.28375\n",
            "Epoch[3720/10000], loss: 0.29802, acc: 0.90667 val_loss: 0.28346\n",
            "Epoch[3730/10000], loss: 0.29774, acc: 0.90667 val_loss: 0.28318\n",
            "Epoch[3740/10000], loss: 0.29746, acc: 0.90667 val_loss: 0.28289\n",
            "Epoch[3750/10000], loss: 0.29718, acc: 0.90667 val_loss: 0.28261\n",
            "Epoch[3760/10000], loss: 0.29690, acc: 0.90667 val_loss: 0.28232\n",
            "Epoch[3770/10000], loss: 0.29663, acc: 0.90667 val_loss: 0.28204\n",
            "Epoch[3780/10000], loss: 0.29635, acc: 0.90667 val_loss: 0.28176\n",
            "Epoch[3790/10000], loss: 0.29607, acc: 0.90667 val_loss: 0.28148\n",
            "Epoch[3800/10000], loss: 0.29580, acc: 0.90667 val_loss: 0.28120\n",
            "Epoch[3810/10000], loss: 0.29553, acc: 0.90667 val_loss: 0.28092\n",
            "Epoch[3820/10000], loss: 0.29525, acc: 0.90667 val_loss: 0.28064\n",
            "Epoch[3830/10000], loss: 0.29498, acc: 0.90667 val_loss: 0.28037\n",
            "Epoch[3840/10000], loss: 0.29471, acc: 0.90667 val_loss: 0.28009\n",
            "Epoch[3850/10000], loss: 0.29444, acc: 0.90667 val_loss: 0.27982\n",
            "Epoch[3860/10000], loss: 0.29418, acc: 0.90667 val_loss: 0.27954\n",
            "Epoch[3870/10000], loss: 0.29391, acc: 0.90667 val_loss: 0.27927\n",
            "Epoch[3880/10000], loss: 0.29364, acc: 0.90667 val_loss: 0.27900\n",
            "Epoch[3890/10000], loss: 0.29338, acc: 0.90667 val_loss: 0.27873\n",
            "Epoch[3900/10000], loss: 0.29311, acc: 0.90667 val_loss: 0.27846\n",
            "Epoch[3910/10000], loss: 0.29285, acc: 0.90667 val_loss: 0.27819\n",
            "Epoch[3920/10000], loss: 0.29258, acc: 0.90667 val_loss: 0.27792\n",
            "Epoch[3930/10000], loss: 0.29232, acc: 0.90667 val_loss: 0.27766\n",
            "Epoch[3940/10000], loss: 0.29206, acc: 0.90667 val_loss: 0.27739\n",
            "Epoch[3950/10000], loss: 0.29180, acc: 0.90667 val_loss: 0.27712\n",
            "Epoch[3960/10000], loss: 0.29154, acc: 0.90667 val_loss: 0.27686\n",
            "Epoch[3970/10000], loss: 0.29128, acc: 0.90667 val_loss: 0.27660\n",
            "Epoch[3980/10000], loss: 0.29103, acc: 0.90667 val_loss: 0.27633\n",
            "Epoch[3990/10000], loss: 0.29077, acc: 0.90667 val_loss: 0.27607\n",
            "Epoch[4000/10000], loss: 0.29052, acc: 0.90667 val_loss: 0.27581\n",
            "Epoch[4010/10000], loss: 0.29026, acc: 0.90667 val_loss: 0.27555\n",
            "Epoch[4020/10000], loss: 0.29001, acc: 0.90667 val_loss: 0.27529\n",
            "Epoch[4030/10000], loss: 0.28975, acc: 0.90667 val_loss: 0.27504\n",
            "Epoch[4040/10000], loss: 0.28950, acc: 0.90667 val_loss: 0.27478\n",
            "Epoch[4050/10000], loss: 0.28925, acc: 0.90667 val_loss: 0.27452\n",
            "Epoch[4060/10000], loss: 0.28900, acc: 0.90667 val_loss: 0.27427\n",
            "Epoch[4070/10000], loss: 0.28875, acc: 0.90667 val_loss: 0.27401\n",
            "Epoch[4080/10000], loss: 0.28850, acc: 0.90667 val_loss: 0.27376\n",
            "Epoch[4090/10000], loss: 0.28826, acc: 0.90667 val_loss: 0.27351\n",
            "Epoch[4100/10000], loss: 0.28801, acc: 0.90667 val_loss: 0.27325\n",
            "Epoch[4110/10000], loss: 0.28776, acc: 0.90667 val_loss: 0.27300\n",
            "Epoch[4120/10000], loss: 0.28752, acc: 0.90667 val_loss: 0.27275\n",
            "Epoch[4130/10000], loss: 0.28727, acc: 0.90667 val_loss: 0.27250\n",
            "Epoch[4140/10000], loss: 0.28703, acc: 0.90667 val_loss: 0.27225\n",
            "Epoch[4150/10000], loss: 0.28679, acc: 0.90667 val_loss: 0.27200\n",
            "Epoch[4160/10000], loss: 0.28654, acc: 0.90667 val_loss: 0.27176\n",
            "Epoch[4170/10000], loss: 0.28630, acc: 0.90667 val_loss: 0.27151\n",
            "Epoch[4180/10000], loss: 0.28606, acc: 0.90667 val_loss: 0.27127\n",
            "Epoch[4190/10000], loss: 0.28582, acc: 0.90667 val_loss: 0.27102\n",
            "Epoch[4200/10000], loss: 0.28559, acc: 0.90667 val_loss: 0.27078\n",
            "Epoch[4210/10000], loss: 0.28535, acc: 0.90667 val_loss: 0.27053\n",
            "Epoch[4220/10000], loss: 0.28511, acc: 0.90667 val_loss: 0.27029\n",
            "Epoch[4230/10000], loss: 0.28487, acc: 0.90667 val_loss: 0.27005\n",
            "Epoch[4240/10000], loss: 0.28464, acc: 0.90667 val_loss: 0.26981\n",
            "Epoch[4250/10000], loss: 0.28440, acc: 0.90667 val_loss: 0.26957\n",
            "Epoch[4260/10000], loss: 0.28417, acc: 0.90667 val_loss: 0.26933\n",
            "Epoch[4270/10000], loss: 0.28394, acc: 0.90667 val_loss: 0.26909\n",
            "Epoch[4280/10000], loss: 0.28370, acc: 0.90667 val_loss: 0.26885\n",
            "Epoch[4290/10000], loss: 0.28347, acc: 0.90667 val_loss: 0.26862\n",
            "Epoch[4300/10000], loss: 0.28324, acc: 0.90667 val_loss: 0.26838\n",
            "Epoch[4310/10000], loss: 0.28301, acc: 0.90667 val_loss: 0.26815\n",
            "Epoch[4320/10000], loss: 0.28278, acc: 0.90667 val_loss: 0.26791\n",
            "Epoch[4330/10000], loss: 0.28255, acc: 0.90667 val_loss: 0.26768\n",
            "Epoch[4340/10000], loss: 0.28233, acc: 0.90667 val_loss: 0.26744\n",
            "Epoch[4350/10000], loss: 0.28210, acc: 0.90667 val_loss: 0.26721\n",
            "Epoch[4360/10000], loss: 0.28187, acc: 0.90667 val_loss: 0.26698\n",
            "Epoch[4370/10000], loss: 0.28165, acc: 0.90667 val_loss: 0.26675\n",
            "Epoch[4380/10000], loss: 0.28142, acc: 0.90667 val_loss: 0.26652\n",
            "Epoch[4390/10000], loss: 0.28120, acc: 0.90667 val_loss: 0.26629\n",
            "Epoch[4400/10000], loss: 0.28098, acc: 0.90667 val_loss: 0.26606\n",
            "Epoch[4410/10000], loss: 0.28075, acc: 0.90667 val_loss: 0.26583\n",
            "Epoch[4420/10000], loss: 0.28053, acc: 0.90667 val_loss: 0.26560\n",
            "Epoch[4430/10000], loss: 0.28031, acc: 0.90667 val_loss: 0.26538\n",
            "Epoch[4440/10000], loss: 0.28009, acc: 0.90667 val_loss: 0.26515\n",
            "Epoch[4450/10000], loss: 0.27987, acc: 0.90667 val_loss: 0.26493\n",
            "Epoch[4460/10000], loss: 0.27965, acc: 0.90667 val_loss: 0.26470\n",
            "Epoch[4470/10000], loss: 0.27943, acc: 0.90667 val_loss: 0.26448\n",
            "Epoch[4480/10000], loss: 0.27922, acc: 0.90667 val_loss: 0.26425\n",
            "Epoch[4490/10000], loss: 0.27900, acc: 0.90667 val_loss: 0.26403\n",
            "Epoch[4500/10000], loss: 0.27878, acc: 0.90667 val_loss: 0.26381\n",
            "Epoch[4510/10000], loss: 0.27857, acc: 0.90667 val_loss: 0.26359\n",
            "Epoch[4520/10000], loss: 0.27835, acc: 0.90667 val_loss: 0.26337\n",
            "Epoch[4530/10000], loss: 0.27814, acc: 0.90667 val_loss: 0.26315\n",
            "Epoch[4540/10000], loss: 0.27792, acc: 0.90667 val_loss: 0.26293\n",
            "Epoch[4550/10000], loss: 0.27771, acc: 0.90667 val_loss: 0.26271\n",
            "Epoch[4560/10000], loss: 0.27750, acc: 0.90667 val_loss: 0.26249\n",
            "Epoch[4570/10000], loss: 0.27729, acc: 0.90667 val_loss: 0.26228\n",
            "Epoch[4580/10000], loss: 0.27708, acc: 0.90667 val_loss: 0.26206\n",
            "Epoch[4590/10000], loss: 0.27687, acc: 0.90667 val_loss: 0.26185\n",
            "Epoch[4600/10000], loss: 0.27666, acc: 0.90667 val_loss: 0.26163\n",
            "Epoch[4610/10000], loss: 0.27645, acc: 0.90667 val_loss: 0.26142\n",
            "Epoch[4620/10000], loss: 0.27624, acc: 0.90667 val_loss: 0.26120\n",
            "Epoch[4630/10000], loss: 0.27603, acc: 0.90667 val_loss: 0.26099\n",
            "Epoch[4640/10000], loss: 0.27583, acc: 0.90667 val_loss: 0.26078\n",
            "Epoch[4650/10000], loss: 0.27562, acc: 0.90667 val_loss: 0.26057\n",
            "Epoch[4660/10000], loss: 0.27541, acc: 0.90667 val_loss: 0.26035\n",
            "Epoch[4670/10000], loss: 0.27521, acc: 0.90667 val_loss: 0.26014\n",
            "Epoch[4680/10000], loss: 0.27500, acc: 0.90667 val_loss: 0.25993\n",
            "Epoch[4690/10000], loss: 0.27480, acc: 0.90667 val_loss: 0.25973\n",
            "Epoch[4700/10000], loss: 0.27460, acc: 0.90667 val_loss: 0.25952\n",
            "Epoch[4710/10000], loss: 0.27440, acc: 0.90667 val_loss: 0.25931\n",
            "Epoch[4720/10000], loss: 0.27419, acc: 0.90667 val_loss: 0.25910\n",
            "Epoch[4730/10000], loss: 0.27399, acc: 0.90667 val_loss: 0.25889\n",
            "Epoch[4740/10000], loss: 0.27379, acc: 0.90667 val_loss: 0.25869\n",
            "Epoch[4750/10000], loss: 0.27359, acc: 0.90667 val_loss: 0.25848\n",
            "Epoch[4760/10000], loss: 0.27339, acc: 0.90667 val_loss: 0.25828\n",
            "Epoch[4770/10000], loss: 0.27319, acc: 0.90667 val_loss: 0.25807\n",
            "Epoch[4780/10000], loss: 0.27300, acc: 0.90667 val_loss: 0.25787\n",
            "Epoch[4790/10000], loss: 0.27280, acc: 0.90667 val_loss: 0.25767\n",
            "Epoch[4800/10000], loss: 0.27260, acc: 0.90667 val_loss: 0.25746\n",
            "Epoch[4810/10000], loss: 0.27241, acc: 0.90667 val_loss: 0.25726\n",
            "Epoch[4820/10000], loss: 0.27221, acc: 0.90667 val_loss: 0.25706\n",
            "Epoch[4830/10000], loss: 0.27202, acc: 0.90667 val_loss: 0.25686\n",
            "Epoch[4840/10000], loss: 0.27182, acc: 0.90667 val_loss: 0.25666\n",
            "Epoch[4850/10000], loss: 0.27163, acc: 0.90667 val_loss: 0.25646\n",
            "Epoch[4860/10000], loss: 0.27143, acc: 0.90667 val_loss: 0.25626\n",
            "Epoch[4870/10000], loss: 0.27124, acc: 0.90667 val_loss: 0.25606\n",
            "Epoch[4880/10000], loss: 0.27105, acc: 0.90667 val_loss: 0.25587\n",
            "Epoch[4890/10000], loss: 0.27086, acc: 0.90667 val_loss: 0.25567\n",
            "Epoch[4900/10000], loss: 0.27067, acc: 0.90667 val_loss: 0.25547\n",
            "Epoch[4910/10000], loss: 0.27048, acc: 0.90667 val_loss: 0.25528\n",
            "Epoch[4920/10000], loss: 0.27029, acc: 0.90667 val_loss: 0.25508\n",
            "Epoch[4930/10000], loss: 0.27010, acc: 0.90667 val_loss: 0.25489\n",
            "Epoch[4940/10000], loss: 0.26991, acc: 0.90667 val_loss: 0.25469\n",
            "Epoch[4950/10000], loss: 0.26972, acc: 0.90667 val_loss: 0.25450\n",
            "Epoch[4960/10000], loss: 0.26953, acc: 0.90667 val_loss: 0.25431\n",
            "Epoch[4970/10000], loss: 0.26935, acc: 0.90667 val_loss: 0.25411\n",
            "Epoch[4980/10000], loss: 0.26916, acc: 0.90667 val_loss: 0.25392\n",
            "Epoch[4990/10000], loss: 0.26897, acc: 0.90667 val_loss: 0.25373\n",
            "Epoch[5000/10000], loss: 0.26879, acc: 0.90667 val_loss: 0.25354\n",
            "Epoch[5010/10000], loss: 0.26860, acc: 0.90667 val_loss: 0.25335\n",
            "Epoch[5020/10000], loss: 0.26842, acc: 0.90667 val_loss: 0.25316\n",
            "Epoch[5030/10000], loss: 0.26824, acc: 0.90667 val_loss: 0.25297\n",
            "Epoch[5040/10000], loss: 0.26805, acc: 0.90667 val_loss: 0.25278\n",
            "Epoch[5050/10000], loss: 0.26787, acc: 0.90667 val_loss: 0.25259\n",
            "Epoch[5060/10000], loss: 0.26769, acc: 0.90667 val_loss: 0.25240\n",
            "Epoch[5070/10000], loss: 0.26751, acc: 0.90667 val_loss: 0.25222\n",
            "Epoch[5080/10000], loss: 0.26733, acc: 0.90667 val_loss: 0.25203\n",
            "Epoch[5090/10000], loss: 0.26715, acc: 0.90667 val_loss: 0.25184\n",
            "Epoch[5100/10000], loss: 0.26697, acc: 0.90667 val_loss: 0.25166\n",
            "Epoch[5110/10000], loss: 0.26679, acc: 0.90667 val_loss: 0.25147\n",
            "Epoch[5120/10000], loss: 0.26661, acc: 0.90667 val_loss: 0.25129\n",
            "Epoch[5130/10000], loss: 0.26643, acc: 0.90667 val_loss: 0.25111\n",
            "Epoch[5140/10000], loss: 0.26625, acc: 0.90667 val_loss: 0.25092\n",
            "Epoch[5150/10000], loss: 0.26608, acc: 0.90667 val_loss: 0.25074\n",
            "Epoch[5160/10000], loss: 0.26590, acc: 0.90667 val_loss: 0.25056\n",
            "Epoch[5170/10000], loss: 0.26572, acc: 0.90667 val_loss: 0.25037\n",
            "Epoch[5180/10000], loss: 0.26555, acc: 0.90667 val_loss: 0.25019\n",
            "Epoch[5190/10000], loss: 0.26537, acc: 0.90667 val_loss: 0.25001\n",
            "Epoch[5200/10000], loss: 0.26520, acc: 0.90667 val_loss: 0.24983\n",
            "Epoch[5210/10000], loss: 0.26502, acc: 0.90667 val_loss: 0.24965\n",
            "Epoch[5220/10000], loss: 0.26485, acc: 0.90667 val_loss: 0.24947\n",
            "Epoch[5230/10000], loss: 0.26468, acc: 0.90667 val_loss: 0.24929\n",
            "Epoch[5240/10000], loss: 0.26450, acc: 0.90667 val_loss: 0.24912\n",
            "Epoch[5250/10000], loss: 0.26433, acc: 0.90667 val_loss: 0.24894\n",
            "Epoch[5260/10000], loss: 0.26416, acc: 0.90667 val_loss: 0.24876\n",
            "Epoch[5270/10000], loss: 0.26399, acc: 0.90667 val_loss: 0.24858\n",
            "Epoch[5280/10000], loss: 0.26382, acc: 0.90667 val_loss: 0.24841\n",
            "Epoch[5290/10000], loss: 0.26365, acc: 0.90667 val_loss: 0.24823\n",
            "Epoch[5300/10000], loss: 0.26348, acc: 0.90667 val_loss: 0.24806\n",
            "Epoch[5310/10000], loss: 0.26331, acc: 0.90667 val_loss: 0.24788\n",
            "Epoch[5320/10000], loss: 0.26314, acc: 0.90667 val_loss: 0.24771\n",
            "Epoch[5330/10000], loss: 0.26297, acc: 0.90667 val_loss: 0.24753\n",
            "Epoch[5340/10000], loss: 0.26280, acc: 0.90667 val_loss: 0.24736\n",
            "Epoch[5350/10000], loss: 0.26264, acc: 0.90667 val_loss: 0.24719\n",
            "Epoch[5360/10000], loss: 0.26247, acc: 0.90667 val_loss: 0.24701\n",
            "Epoch[5370/10000], loss: 0.26230, acc: 0.90667 val_loss: 0.24684\n",
            "Epoch[5380/10000], loss: 0.26214, acc: 0.90667 val_loss: 0.24667\n",
            "Epoch[5390/10000], loss: 0.26197, acc: 0.90667 val_loss: 0.24650\n",
            "Epoch[5400/10000], loss: 0.26181, acc: 0.90667 val_loss: 0.24633\n",
            "Epoch[5410/10000], loss: 0.26164, acc: 0.90667 val_loss: 0.24616\n",
            "Epoch[5420/10000], loss: 0.26148, acc: 0.90667 val_loss: 0.24599\n",
            "Epoch[5430/10000], loss: 0.26131, acc: 0.90667 val_loss: 0.24582\n",
            "Epoch[5440/10000], loss: 0.26115, acc: 0.90667 val_loss: 0.24565\n",
            "Epoch[5450/10000], loss: 0.26099, acc: 0.90667 val_loss: 0.24548\n",
            "Epoch[5460/10000], loss: 0.26083, acc: 0.90667 val_loss: 0.24531\n",
            "Epoch[5470/10000], loss: 0.26066, acc: 0.90667 val_loss: 0.24514\n",
            "Epoch[5480/10000], loss: 0.26050, acc: 0.90667 val_loss: 0.24498\n",
            "Epoch[5490/10000], loss: 0.26034, acc: 0.90667 val_loss: 0.24481\n",
            "Epoch[5500/10000], loss: 0.26018, acc: 0.90667 val_loss: 0.24464\n",
            "Epoch[5510/10000], loss: 0.26002, acc: 0.90667 val_loss: 0.24448\n",
            "Epoch[5520/10000], loss: 0.25986, acc: 0.90667 val_loss: 0.24431\n",
            "Epoch[5530/10000], loss: 0.25970, acc: 0.90667 val_loss: 0.24415\n",
            "Epoch[5540/10000], loss: 0.25954, acc: 0.90667 val_loss: 0.24398\n",
            "Epoch[5550/10000], loss: 0.25939, acc: 0.90667 val_loss: 0.24382\n",
            "Epoch[5560/10000], loss: 0.25923, acc: 0.90667 val_loss: 0.24366\n",
            "Epoch[5570/10000], loss: 0.25907, acc: 0.90667 val_loss: 0.24349\n",
            "Epoch[5580/10000], loss: 0.25891, acc: 0.90667 val_loss: 0.24333\n",
            "Epoch[5590/10000], loss: 0.25876, acc: 0.90667 val_loss: 0.24317\n",
            "Epoch[5600/10000], loss: 0.25860, acc: 0.90667 val_loss: 0.24301\n",
            "Epoch[5610/10000], loss: 0.25845, acc: 0.90667 val_loss: 0.24285\n",
            "Epoch[5620/10000], loss: 0.25829, acc: 0.90667 val_loss: 0.24268\n",
            "Epoch[5630/10000], loss: 0.25814, acc: 0.90667 val_loss: 0.24252\n",
            "Epoch[5640/10000], loss: 0.25798, acc: 0.90667 val_loss: 0.24236\n",
            "Epoch[5650/10000], loss: 0.25783, acc: 0.90667 val_loss: 0.24220\n",
            "Epoch[5660/10000], loss: 0.25767, acc: 0.90667 val_loss: 0.24205\n",
            "Epoch[5670/10000], loss: 0.25752, acc: 0.90667 val_loss: 0.24189\n",
            "Epoch[5680/10000], loss: 0.25737, acc: 0.90667 val_loss: 0.24173\n",
            "Epoch[5690/10000], loss: 0.25722, acc: 0.90667 val_loss: 0.24157\n",
            "Epoch[5700/10000], loss: 0.25706, acc: 0.90667 val_loss: 0.24141\n",
            "Epoch[5710/10000], loss: 0.25691, acc: 0.90667 val_loss: 0.24126\n",
            "Epoch[5720/10000], loss: 0.25676, acc: 0.90667 val_loss: 0.24110\n",
            "Epoch[5730/10000], loss: 0.25661, acc: 0.90667 val_loss: 0.24094\n",
            "Epoch[5740/10000], loss: 0.25646, acc: 0.90667 val_loss: 0.24079\n",
            "Epoch[5750/10000], loss: 0.25631, acc: 0.90667 val_loss: 0.24063\n",
            "Epoch[5760/10000], loss: 0.25616, acc: 0.90667 val_loss: 0.24048\n",
            "Epoch[5770/10000], loss: 0.25601, acc: 0.90667 val_loss: 0.24032\n",
            "Epoch[5780/10000], loss: 0.25586, acc: 0.90667 val_loss: 0.24017\n",
            "Epoch[5790/10000], loss: 0.25571, acc: 0.90667 val_loss: 0.24001\n",
            "Epoch[5800/10000], loss: 0.25557, acc: 0.90667 val_loss: 0.23986\n",
            "Epoch[5810/10000], loss: 0.25542, acc: 0.90667 val_loss: 0.23971\n",
            "Epoch[5820/10000], loss: 0.25527, acc: 0.90667 val_loss: 0.23955\n",
            "Epoch[5830/10000], loss: 0.25513, acc: 0.90667 val_loss: 0.23940\n",
            "Epoch[5840/10000], loss: 0.25498, acc: 0.90667 val_loss: 0.23925\n",
            "Epoch[5850/10000], loss: 0.25483, acc: 0.90667 val_loss: 0.23910\n",
            "Epoch[5860/10000], loss: 0.25469, acc: 0.90667 val_loss: 0.23895\n",
            "Epoch[5870/10000], loss: 0.25454, acc: 0.90667 val_loss: 0.23879\n",
            "Epoch[5880/10000], loss: 0.25440, acc: 0.90667 val_loss: 0.23864\n",
            "Epoch[5890/10000], loss: 0.25425, acc: 0.90667 val_loss: 0.23849\n",
            "Epoch[5900/10000], loss: 0.25411, acc: 0.90667 val_loss: 0.23834\n",
            "Epoch[5910/10000], loss: 0.25397, acc: 0.90667 val_loss: 0.23819\n",
            "Epoch[5920/10000], loss: 0.25382, acc: 0.90667 val_loss: 0.23805\n",
            "Epoch[5930/10000], loss: 0.25368, acc: 0.90667 val_loss: 0.23790\n",
            "Epoch[5940/10000], loss: 0.25354, acc: 0.90667 val_loss: 0.23775\n",
            "Epoch[5950/10000], loss: 0.25340, acc: 0.90667 val_loss: 0.23760\n",
            "Epoch[5960/10000], loss: 0.25325, acc: 0.90667 val_loss: 0.23745\n",
            "Epoch[5970/10000], loss: 0.25311, acc: 0.90667 val_loss: 0.23731\n",
            "Epoch[5980/10000], loss: 0.25297, acc: 0.90667 val_loss: 0.23716\n",
            "Epoch[5990/10000], loss: 0.25283, acc: 0.90667 val_loss: 0.23701\n",
            "Epoch[6000/10000], loss: 0.25269, acc: 0.90667 val_loss: 0.23687\n",
            "Epoch[6010/10000], loss: 0.25255, acc: 0.90667 val_loss: 0.23672\n",
            "Epoch[6020/10000], loss: 0.25241, acc: 0.90667 val_loss: 0.23658\n",
            "Epoch[6030/10000], loss: 0.25227, acc: 0.90667 val_loss: 0.23643\n",
            "Epoch[6040/10000], loss: 0.25213, acc: 0.90667 val_loss: 0.23629\n",
            "Epoch[6050/10000], loss: 0.25199, acc: 0.90667 val_loss: 0.23614\n",
            "Epoch[6060/10000], loss: 0.25186, acc: 0.90667 val_loss: 0.23600\n",
            "Epoch[6070/10000], loss: 0.25172, acc: 0.90667 val_loss: 0.23586\n",
            "Epoch[6080/10000], loss: 0.25158, acc: 0.90667 val_loss: 0.23571\n",
            "Epoch[6090/10000], loss: 0.25144, acc: 0.90667 val_loss: 0.23557\n",
            "Epoch[6100/10000], loss: 0.25131, acc: 0.90667 val_loss: 0.23543\n",
            "Epoch[6110/10000], loss: 0.25117, acc: 0.90667 val_loss: 0.23529\n",
            "Epoch[6120/10000], loss: 0.25104, acc: 0.90667 val_loss: 0.23514\n",
            "Epoch[6130/10000], loss: 0.25090, acc: 0.90667 val_loss: 0.23500\n",
            "Epoch[6140/10000], loss: 0.25076, acc: 0.90667 val_loss: 0.23486\n",
            "Epoch[6150/10000], loss: 0.25063, acc: 0.90667 val_loss: 0.23472\n",
            "Epoch[6160/10000], loss: 0.25049, acc: 0.90667 val_loss: 0.23458\n",
            "Epoch[6170/10000], loss: 0.25036, acc: 0.90667 val_loss: 0.23444\n",
            "Epoch[6180/10000], loss: 0.25023, acc: 0.90667 val_loss: 0.23430\n",
            "Epoch[6190/10000], loss: 0.25009, acc: 0.90667 val_loss: 0.23416\n",
            "Epoch[6200/10000], loss: 0.24996, acc: 0.90667 val_loss: 0.23402\n",
            "Epoch[6210/10000], loss: 0.24983, acc: 0.90667 val_loss: 0.23388\n",
            "Epoch[6220/10000], loss: 0.24969, acc: 0.90667 val_loss: 0.23375\n",
            "Epoch[6230/10000], loss: 0.24956, acc: 0.90667 val_loss: 0.23361\n",
            "Epoch[6240/10000], loss: 0.24943, acc: 0.90667 val_loss: 0.23347\n",
            "Epoch[6250/10000], loss: 0.24930, acc: 0.90667 val_loss: 0.23333\n",
            "Epoch[6260/10000], loss: 0.24917, acc: 0.90667 val_loss: 0.23320\n",
            "Epoch[6270/10000], loss: 0.24904, acc: 0.90667 val_loss: 0.23306\n",
            "Epoch[6280/10000], loss: 0.24891, acc: 0.90667 val_loss: 0.23292\n",
            "Epoch[6290/10000], loss: 0.24878, acc: 0.90667 val_loss: 0.23279\n",
            "Epoch[6300/10000], loss: 0.24865, acc: 0.90667 val_loss: 0.23265\n",
            "Epoch[6310/10000], loss: 0.24852, acc: 0.90667 val_loss: 0.23252\n",
            "Epoch[6320/10000], loss: 0.24839, acc: 0.90667 val_loss: 0.23238\n",
            "Epoch[6330/10000], loss: 0.24826, acc: 0.90667 val_loss: 0.23225\n",
            "Epoch[6340/10000], loss: 0.24813, acc: 0.90667 val_loss: 0.23211\n",
            "Epoch[6350/10000], loss: 0.24800, acc: 0.90667 val_loss: 0.23198\n",
            "Epoch[6360/10000], loss: 0.24787, acc: 0.90667 val_loss: 0.23184\n",
            "Epoch[6370/10000], loss: 0.24775, acc: 0.90667 val_loss: 0.23171\n",
            "Epoch[6380/10000], loss: 0.24762, acc: 0.90667 val_loss: 0.23158\n",
            "Epoch[6390/10000], loss: 0.24749, acc: 0.90667 val_loss: 0.23145\n",
            "Epoch[6400/10000], loss: 0.24736, acc: 0.90667 val_loss: 0.23131\n",
            "Epoch[6410/10000], loss: 0.24724, acc: 0.90667 val_loss: 0.23118\n",
            "Epoch[6420/10000], loss: 0.24711, acc: 0.90667 val_loss: 0.23105\n",
            "Epoch[6430/10000], loss: 0.24699, acc: 0.90667 val_loss: 0.23092\n",
            "Epoch[6440/10000], loss: 0.24686, acc: 0.90667 val_loss: 0.23079\n",
            "Epoch[6450/10000], loss: 0.24674, acc: 0.90667 val_loss: 0.23066\n",
            "Epoch[6460/10000], loss: 0.24661, acc: 0.90667 val_loss: 0.23053\n",
            "Epoch[6470/10000], loss: 0.24649, acc: 0.90667 val_loss: 0.23040\n",
            "Epoch[6480/10000], loss: 0.24636, acc: 0.90667 val_loss: 0.23027\n",
            "Epoch[6490/10000], loss: 0.24624, acc: 0.90667 val_loss: 0.23014\n",
            "Epoch[6500/10000], loss: 0.24611, acc: 0.90667 val_loss: 0.23001\n",
            "Epoch[6510/10000], loss: 0.24599, acc: 0.90667 val_loss: 0.22988\n",
            "Epoch[6520/10000], loss: 0.24587, acc: 0.90667 val_loss: 0.22975\n",
            "Epoch[6530/10000], loss: 0.24575, acc: 0.90667 val_loss: 0.22962\n",
            "Epoch[6540/10000], loss: 0.24562, acc: 0.90667 val_loss: 0.22949\n",
            "Epoch[6550/10000], loss: 0.24550, acc: 0.90667 val_loss: 0.22936\n",
            "Epoch[6560/10000], loss: 0.24538, acc: 0.90667 val_loss: 0.22924\n",
            "Epoch[6570/10000], loss: 0.24526, acc: 0.90667 val_loss: 0.22911\n",
            "Epoch[6580/10000], loss: 0.24514, acc: 0.90667 val_loss: 0.22898\n",
            "Epoch[6590/10000], loss: 0.24502, acc: 0.90667 val_loss: 0.22886\n",
            "Epoch[6600/10000], loss: 0.24489, acc: 0.90667 val_loss: 0.22873\n",
            "Epoch[6610/10000], loss: 0.24477, acc: 0.90667 val_loss: 0.22860\n",
            "Epoch[6620/10000], loss: 0.24465, acc: 0.90667 val_loss: 0.22848\n",
            "Epoch[6630/10000], loss: 0.24453, acc: 0.90667 val_loss: 0.22835\n",
            "Epoch[6640/10000], loss: 0.24441, acc: 0.90667 val_loss: 0.22823\n",
            "Epoch[6650/10000], loss: 0.24430, acc: 0.90667 val_loss: 0.22810\n",
            "Epoch[6660/10000], loss: 0.24418, acc: 0.90667 val_loss: 0.22798\n",
            "Epoch[6670/10000], loss: 0.24406, acc: 0.90667 val_loss: 0.22785\n",
            "Epoch[6680/10000], loss: 0.24394, acc: 0.90667 val_loss: 0.22773\n",
            "Epoch[6690/10000], loss: 0.24382, acc: 0.90667 val_loss: 0.22761\n",
            "Epoch[6700/10000], loss: 0.24370, acc: 0.90667 val_loss: 0.22748\n",
            "Epoch[6710/10000], loss: 0.24359, acc: 0.90667 val_loss: 0.22736\n",
            "Epoch[6720/10000], loss: 0.24347, acc: 0.90667 val_loss: 0.22724\n",
            "Epoch[6730/10000], loss: 0.24335, acc: 0.90667 val_loss: 0.22711\n",
            "Epoch[6740/10000], loss: 0.24324, acc: 0.90667 val_loss: 0.22699\n",
            "Epoch[6750/10000], loss: 0.24312, acc: 0.90667 val_loss: 0.22687\n",
            "Epoch[6760/10000], loss: 0.24300, acc: 0.90667 val_loss: 0.22675\n",
            "Epoch[6770/10000], loss: 0.24289, acc: 0.90667 val_loss: 0.22663\n",
            "Epoch[6780/10000], loss: 0.24277, acc: 0.90667 val_loss: 0.22651\n",
            "Epoch[6790/10000], loss: 0.24266, acc: 0.90667 val_loss: 0.22638\n",
            "Epoch[6800/10000], loss: 0.24254, acc: 0.90667 val_loss: 0.22626\n",
            "Epoch[6810/10000], loss: 0.24243, acc: 0.90667 val_loss: 0.22614\n",
            "Epoch[6820/10000], loss: 0.24231, acc: 0.90667 val_loss: 0.22602\n",
            "Epoch[6830/10000], loss: 0.24220, acc: 0.90667 val_loss: 0.22590\n",
            "Epoch[6840/10000], loss: 0.24208, acc: 0.90667 val_loss: 0.22578\n",
            "Epoch[6850/10000], loss: 0.24197, acc: 0.90667 val_loss: 0.22566\n",
            "Epoch[6860/10000], loss: 0.24186, acc: 0.90667 val_loss: 0.22555\n",
            "Epoch[6870/10000], loss: 0.24174, acc: 0.90667 val_loss: 0.22543\n",
            "Epoch[6880/10000], loss: 0.24163, acc: 0.90667 val_loss: 0.22531\n",
            "Epoch[6890/10000], loss: 0.24152, acc: 0.90667 val_loss: 0.22519\n",
            "Epoch[6900/10000], loss: 0.24141, acc: 0.90667 val_loss: 0.22507\n",
            "Epoch[6910/10000], loss: 0.24129, acc: 0.90667 val_loss: 0.22495\n",
            "Epoch[6920/10000], loss: 0.24118, acc: 0.90667 val_loss: 0.22484\n",
            "Epoch[6930/10000], loss: 0.24107, acc: 0.90667 val_loss: 0.22472\n",
            "Epoch[6940/10000], loss: 0.24096, acc: 0.90667 val_loss: 0.22460\n",
            "Epoch[6950/10000], loss: 0.24085, acc: 0.90667 val_loss: 0.22449\n",
            "Epoch[6960/10000], loss: 0.24074, acc: 0.90667 val_loss: 0.22437\n",
            "Epoch[6970/10000], loss: 0.24063, acc: 0.90667 val_loss: 0.22425\n",
            "Epoch[6980/10000], loss: 0.24052, acc: 0.90667 val_loss: 0.22414\n",
            "Epoch[6990/10000], loss: 0.24041, acc: 0.90667 val_loss: 0.22402\n",
            "Epoch[7000/10000], loss: 0.24030, acc: 0.90667 val_loss: 0.22391\n",
            "Epoch[7010/10000], loss: 0.24019, acc: 0.90667 val_loss: 0.22379\n",
            "Epoch[7020/10000], loss: 0.24008, acc: 0.90667 val_loss: 0.22368\n",
            "Epoch[7030/10000], loss: 0.23997, acc: 0.90667 val_loss: 0.22356\n",
            "Epoch[7040/10000], loss: 0.23986, acc: 0.90667 val_loss: 0.22345\n",
            "Epoch[7050/10000], loss: 0.23975, acc: 0.90667 val_loss: 0.22333\n",
            "Epoch[7060/10000], loss: 0.23964, acc: 0.90667 val_loss: 0.22322\n",
            "Epoch[7070/10000], loss: 0.23953, acc: 0.90667 val_loss: 0.22311\n",
            "Epoch[7080/10000], loss: 0.23943, acc: 0.90667 val_loss: 0.22299\n",
            "Epoch[7090/10000], loss: 0.23932, acc: 0.90667 val_loss: 0.22288\n",
            "Epoch[7100/10000], loss: 0.23921, acc: 0.90667 val_loss: 0.22277\n",
            "Epoch[7110/10000], loss: 0.23910, acc: 0.90667 val_loss: 0.22265\n",
            "Epoch[7120/10000], loss: 0.23900, acc: 0.90667 val_loss: 0.22254\n",
            "Epoch[7130/10000], loss: 0.23889, acc: 0.90667 val_loss: 0.22243\n",
            "Epoch[7140/10000], loss: 0.23879, acc: 0.90667 val_loss: 0.22232\n",
            "Epoch[7150/10000], loss: 0.23868, acc: 0.90667 val_loss: 0.22221\n",
            "Epoch[7160/10000], loss: 0.23857, acc: 0.90667 val_loss: 0.22209\n",
            "Epoch[7170/10000], loss: 0.23847, acc: 0.90667 val_loss: 0.22198\n",
            "Epoch[7180/10000], loss: 0.23836, acc: 0.90667 val_loss: 0.22187\n",
            "Epoch[7190/10000], loss: 0.23826, acc: 0.90667 val_loss: 0.22176\n",
            "Epoch[7200/10000], loss: 0.23815, acc: 0.90667 val_loss: 0.22165\n",
            "Epoch[7210/10000], loss: 0.23805, acc: 0.90667 val_loss: 0.22154\n",
            "Epoch[7220/10000], loss: 0.23794, acc: 0.90667 val_loss: 0.22143\n",
            "Epoch[7230/10000], loss: 0.23784, acc: 0.90667 val_loss: 0.22132\n",
            "Epoch[7240/10000], loss: 0.23774, acc: 0.90667 val_loss: 0.22121\n",
            "Epoch[7250/10000], loss: 0.23763, acc: 0.90667 val_loss: 0.22110\n",
            "Epoch[7260/10000], loss: 0.23753, acc: 0.90667 val_loss: 0.22099\n",
            "Epoch[7270/10000], loss: 0.23742, acc: 0.90667 val_loss: 0.22088\n",
            "Epoch[7280/10000], loss: 0.23732, acc: 0.90667 val_loss: 0.22078\n",
            "Epoch[7290/10000], loss: 0.23722, acc: 0.90667 val_loss: 0.22067\n",
            "Epoch[7300/10000], loss: 0.23712, acc: 0.90667 val_loss: 0.22056\n",
            "Epoch[7310/10000], loss: 0.23701, acc: 0.90667 val_loss: 0.22045\n",
            "Epoch[7320/10000], loss: 0.23691, acc: 0.90667 val_loss: 0.22034\n",
            "Epoch[7330/10000], loss: 0.23681, acc: 0.90667 val_loss: 0.22024\n",
            "Epoch[7340/10000], loss: 0.23671, acc: 0.90667 val_loss: 0.22013\n",
            "Epoch[7350/10000], loss: 0.23661, acc: 0.90667 val_loss: 0.22002\n",
            "Epoch[7360/10000], loss: 0.23651, acc: 0.90667 val_loss: 0.21992\n",
            "Epoch[7370/10000], loss: 0.23640, acc: 0.90667 val_loss: 0.21981\n",
            "Epoch[7380/10000], loss: 0.23630, acc: 0.90667 val_loss: 0.21970\n",
            "Epoch[7390/10000], loss: 0.23620, acc: 0.90667 val_loss: 0.21960\n",
            "Epoch[7400/10000], loss: 0.23610, acc: 0.90667 val_loss: 0.21949\n",
            "Epoch[7410/10000], loss: 0.23600, acc: 0.90667 val_loss: 0.21939\n",
            "Epoch[7420/10000], loss: 0.23590, acc: 0.90667 val_loss: 0.21928\n",
            "Epoch[7430/10000], loss: 0.23580, acc: 0.90667 val_loss: 0.21918\n",
            "Epoch[7440/10000], loss: 0.23570, acc: 0.90667 val_loss: 0.21907\n",
            "Epoch[7450/10000], loss: 0.23560, acc: 0.90667 val_loss: 0.21897\n",
            "Epoch[7460/10000], loss: 0.23551, acc: 0.90667 val_loss: 0.21886\n",
            "Epoch[7470/10000], loss: 0.23541, acc: 0.90667 val_loss: 0.21876\n",
            "Epoch[7480/10000], loss: 0.23531, acc: 0.90667 val_loss: 0.21865\n",
            "Epoch[7490/10000], loss: 0.23521, acc: 0.90667 val_loss: 0.21855\n",
            "Epoch[7500/10000], loss: 0.23511, acc: 0.90667 val_loss: 0.21845\n",
            "Epoch[7510/10000], loss: 0.23501, acc: 0.90667 val_loss: 0.21834\n",
            "Epoch[7520/10000], loss: 0.23492, acc: 0.90667 val_loss: 0.21824\n",
            "Epoch[7530/10000], loss: 0.23482, acc: 0.90667 val_loss: 0.21814\n",
            "Epoch[7540/10000], loss: 0.23472, acc: 0.90667 val_loss: 0.21803\n",
            "Epoch[7550/10000], loss: 0.23462, acc: 0.90667 val_loss: 0.21793\n",
            "Epoch[7560/10000], loss: 0.23453, acc: 0.90667 val_loss: 0.21783\n",
            "Epoch[7570/10000], loss: 0.23443, acc: 0.90667 val_loss: 0.21773\n",
            "Epoch[7580/10000], loss: 0.23433, acc: 0.90667 val_loss: 0.21762\n",
            "Epoch[7590/10000], loss: 0.23424, acc: 0.90667 val_loss: 0.21752\n",
            "Epoch[7600/10000], loss: 0.23414, acc: 0.90667 val_loss: 0.21742\n",
            "Epoch[7610/10000], loss: 0.23405, acc: 0.90667 val_loss: 0.21732\n",
            "Epoch[7620/10000], loss: 0.23395, acc: 0.90667 val_loss: 0.21722\n",
            "Epoch[7630/10000], loss: 0.23385, acc: 0.90667 val_loss: 0.21712\n",
            "Epoch[7640/10000], loss: 0.23376, acc: 0.90667 val_loss: 0.21702\n",
            "Epoch[7650/10000], loss: 0.23366, acc: 0.90667 val_loss: 0.21692\n",
            "Epoch[7660/10000], loss: 0.23357, acc: 0.90667 val_loss: 0.21682\n",
            "Epoch[7670/10000], loss: 0.23348, acc: 0.90667 val_loss: 0.21672\n",
            "Epoch[7680/10000], loss: 0.23338, acc: 0.90667 val_loss: 0.21662\n",
            "Epoch[7690/10000], loss: 0.23329, acc: 0.90667 val_loss: 0.21652\n",
            "Epoch[7700/10000], loss: 0.23319, acc: 0.90667 val_loss: 0.21642\n",
            "Epoch[7710/10000], loss: 0.23310, acc: 0.90667 val_loss: 0.21632\n",
            "Epoch[7720/10000], loss: 0.23301, acc: 0.90667 val_loss: 0.21622\n",
            "Epoch[7730/10000], loss: 0.23291, acc: 0.90667 val_loss: 0.21612\n",
            "Epoch[7740/10000], loss: 0.23282, acc: 0.90667 val_loss: 0.21602\n",
            "Epoch[7750/10000], loss: 0.23273, acc: 0.90667 val_loss: 0.21592\n",
            "Epoch[7760/10000], loss: 0.23263, acc: 0.90667 val_loss: 0.21582\n",
            "Epoch[7770/10000], loss: 0.23254, acc: 0.90667 val_loss: 0.21573\n",
            "Epoch[7780/10000], loss: 0.23245, acc: 0.90667 val_loss: 0.21563\n",
            "Epoch[7790/10000], loss: 0.23236, acc: 0.90667 val_loss: 0.21553\n",
            "Epoch[7800/10000], loss: 0.23226, acc: 0.90667 val_loss: 0.21543\n",
            "Epoch[7810/10000], loss: 0.23217, acc: 0.90667 val_loss: 0.21534\n",
            "Epoch[7820/10000], loss: 0.23208, acc: 0.90667 val_loss: 0.21524\n",
            "Epoch[7830/10000], loss: 0.23199, acc: 0.90667 val_loss: 0.21514\n",
            "Epoch[7840/10000], loss: 0.23190, acc: 0.90667 val_loss: 0.21505\n",
            "Epoch[7850/10000], loss: 0.23181, acc: 0.90667 val_loss: 0.21495\n",
            "Epoch[7860/10000], loss: 0.23172, acc: 0.90667 val_loss: 0.21485\n",
            "Epoch[7870/10000], loss: 0.23162, acc: 0.90667 val_loss: 0.21476\n",
            "Epoch[7880/10000], loss: 0.23153, acc: 0.90667 val_loss: 0.21466\n",
            "Epoch[7890/10000], loss: 0.23144, acc: 0.90667 val_loss: 0.21457\n",
            "Epoch[7900/10000], loss: 0.23135, acc: 0.90667 val_loss: 0.21447\n",
            "Epoch[7910/10000], loss: 0.23126, acc: 0.90667 val_loss: 0.21437\n",
            "Epoch[7920/10000], loss: 0.23117, acc: 0.90667 val_loss: 0.21428\n",
            "Epoch[7930/10000], loss: 0.23108, acc: 0.90667 val_loss: 0.21418\n",
            "Epoch[7940/10000], loss: 0.23099, acc: 0.90667 val_loss: 0.21409\n",
            "Epoch[7950/10000], loss: 0.23091, acc: 0.90667 val_loss: 0.21400\n",
            "Epoch[7960/10000], loss: 0.23082, acc: 0.90667 val_loss: 0.21390\n",
            "Epoch[7970/10000], loss: 0.23073, acc: 0.90667 val_loss: 0.21381\n",
            "Epoch[7980/10000], loss: 0.23064, acc: 0.90667 val_loss: 0.21371\n",
            "Epoch[7990/10000], loss: 0.23055, acc: 0.90667 val_loss: 0.21362\n",
            "Epoch[8000/10000], loss: 0.23046, acc: 0.90667 val_loss: 0.21353\n",
            "Epoch[8010/10000], loss: 0.23037, acc: 0.90667 val_loss: 0.21343\n",
            "Epoch[8020/10000], loss: 0.23029, acc: 0.90667 val_loss: 0.21334\n",
            "Epoch[8030/10000], loss: 0.23020, acc: 0.90667 val_loss: 0.21325\n",
            "Epoch[8040/10000], loss: 0.23011, acc: 0.90667 val_loss: 0.21315\n",
            "Epoch[8050/10000], loss: 0.23002, acc: 0.90667 val_loss: 0.21306\n",
            "Epoch[8060/10000], loss: 0.22994, acc: 0.90667 val_loss: 0.21297\n",
            "Epoch[8070/10000], loss: 0.22985, acc: 0.90667 val_loss: 0.21288\n",
            "Epoch[8080/10000], loss: 0.22976, acc: 0.90667 val_loss: 0.21278\n",
            "Epoch[8090/10000], loss: 0.22968, acc: 0.90667 val_loss: 0.21269\n",
            "Epoch[8100/10000], loss: 0.22959, acc: 0.90667 val_loss: 0.21260\n",
            "Epoch[8110/10000], loss: 0.22950, acc: 0.90667 val_loss: 0.21251\n",
            "Epoch[8120/10000], loss: 0.22942, acc: 0.90667 val_loss: 0.21242\n",
            "Epoch[8130/10000], loss: 0.22933, acc: 0.90667 val_loss: 0.21233\n",
            "Epoch[8140/10000], loss: 0.22925, acc: 0.90667 val_loss: 0.21223\n",
            "Epoch[8150/10000], loss: 0.22916, acc: 0.90667 val_loss: 0.21214\n",
            "Epoch[8160/10000], loss: 0.22907, acc: 0.90667 val_loss: 0.21205\n",
            "Epoch[8170/10000], loss: 0.22899, acc: 0.90667 val_loss: 0.21196\n",
            "Epoch[8180/10000], loss: 0.22890, acc: 0.90667 val_loss: 0.21187\n",
            "Epoch[8190/10000], loss: 0.22882, acc: 0.90667 val_loss: 0.21178\n",
            "Epoch[8200/10000], loss: 0.22873, acc: 0.90667 val_loss: 0.21169\n",
            "Epoch[8210/10000], loss: 0.22865, acc: 0.90667 val_loss: 0.21160\n",
            "Epoch[8220/10000], loss: 0.22857, acc: 0.90667 val_loss: 0.21151\n",
            "Epoch[8230/10000], loss: 0.22848, acc: 0.90667 val_loss: 0.21142\n",
            "Epoch[8240/10000], loss: 0.22840, acc: 0.90667 val_loss: 0.21133\n",
            "Epoch[8250/10000], loss: 0.22831, acc: 0.90667 val_loss: 0.21124\n",
            "Epoch[8260/10000], loss: 0.22823, acc: 0.90667 val_loss: 0.21115\n",
            "Epoch[8270/10000], loss: 0.22815, acc: 0.90667 val_loss: 0.21107\n",
            "Epoch[8280/10000], loss: 0.22806, acc: 0.90667 val_loss: 0.21098\n",
            "Epoch[8290/10000], loss: 0.22798, acc: 0.90667 val_loss: 0.21089\n",
            "Epoch[8300/10000], loss: 0.22790, acc: 0.90667 val_loss: 0.21080\n",
            "Epoch[8310/10000], loss: 0.22781, acc: 0.90667 val_loss: 0.21071\n",
            "Epoch[8320/10000], loss: 0.22773, acc: 0.90667 val_loss: 0.21062\n",
            "Epoch[8330/10000], loss: 0.22765, acc: 0.90667 val_loss: 0.21054\n",
            "Epoch[8340/10000], loss: 0.22757, acc: 0.90667 val_loss: 0.21045\n",
            "Epoch[8350/10000], loss: 0.22748, acc: 0.90667 val_loss: 0.21036\n",
            "Epoch[8360/10000], loss: 0.22740, acc: 0.90667 val_loss: 0.21027\n",
            "Epoch[8370/10000], loss: 0.22732, acc: 0.90667 val_loss: 0.21019\n",
            "Epoch[8380/10000], loss: 0.22724, acc: 0.90667 val_loss: 0.21010\n",
            "Epoch[8390/10000], loss: 0.22716, acc: 0.90667 val_loss: 0.21001\n",
            "Epoch[8400/10000], loss: 0.22708, acc: 0.90667 val_loss: 0.20993\n",
            "Epoch[8410/10000], loss: 0.22699, acc: 0.90667 val_loss: 0.20984\n",
            "Epoch[8420/10000], loss: 0.22691, acc: 0.90667 val_loss: 0.20975\n",
            "Epoch[8430/10000], loss: 0.22683, acc: 0.90667 val_loss: 0.20967\n",
            "Epoch[8440/10000], loss: 0.22675, acc: 0.90667 val_loss: 0.20958\n",
            "Epoch[8450/10000], loss: 0.22667, acc: 0.90667 val_loss: 0.20949\n",
            "Epoch[8460/10000], loss: 0.22659, acc: 0.90667 val_loss: 0.20941\n",
            "Epoch[8470/10000], loss: 0.22651, acc: 0.90667 val_loss: 0.20932\n",
            "Epoch[8480/10000], loss: 0.22643, acc: 0.90667 val_loss: 0.20924\n",
            "Epoch[8490/10000], loss: 0.22635, acc: 0.90667 val_loss: 0.20915\n",
            "Epoch[8500/10000], loss: 0.22627, acc: 0.90667 val_loss: 0.20907\n",
            "Epoch[8510/10000], loss: 0.22619, acc: 0.90667 val_loss: 0.20898\n",
            "Epoch[8520/10000], loss: 0.22611, acc: 0.90667 val_loss: 0.20890\n",
            "Epoch[8530/10000], loss: 0.22603, acc: 0.90667 val_loss: 0.20881\n",
            "Epoch[8540/10000], loss: 0.22595, acc: 0.90667 val_loss: 0.20873\n",
            "Epoch[8550/10000], loss: 0.22587, acc: 0.90667 val_loss: 0.20865\n",
            "Epoch[8560/10000], loss: 0.22579, acc: 0.90667 val_loss: 0.20856\n",
            "Epoch[8570/10000], loss: 0.22572, acc: 0.90667 val_loss: 0.20848\n",
            "Epoch[8580/10000], loss: 0.22564, acc: 0.90667 val_loss: 0.20839\n",
            "Epoch[8590/10000], loss: 0.22556, acc: 0.90667 val_loss: 0.20831\n",
            "Epoch[8600/10000], loss: 0.22548, acc: 0.90667 val_loss: 0.20823\n",
            "Epoch[8610/10000], loss: 0.22540, acc: 0.90667 val_loss: 0.20814\n",
            "Epoch[8620/10000], loss: 0.22532, acc: 0.90667 val_loss: 0.20806\n",
            "Epoch[8630/10000], loss: 0.22525, acc: 0.90667 val_loss: 0.20798\n",
            "Epoch[8640/10000], loss: 0.22517, acc: 0.90667 val_loss: 0.20789\n",
            "Epoch[8650/10000], loss: 0.22509, acc: 0.90667 val_loss: 0.20781\n",
            "Epoch[8660/10000], loss: 0.22501, acc: 0.90667 val_loss: 0.20773\n",
            "Epoch[8670/10000], loss: 0.22494, acc: 0.90667 val_loss: 0.20765\n",
            "Epoch[8680/10000], loss: 0.22486, acc: 0.90667 val_loss: 0.20756\n",
            "Epoch[8690/10000], loss: 0.22478, acc: 0.90667 val_loss: 0.20748\n",
            "Epoch[8700/10000], loss: 0.22471, acc: 0.90667 val_loss: 0.20740\n",
            "Epoch[8710/10000], loss: 0.22463, acc: 0.90667 val_loss: 0.20732\n",
            "Epoch[8720/10000], loss: 0.22455, acc: 0.90667 val_loss: 0.20724\n",
            "Epoch[8730/10000], loss: 0.22448, acc: 0.90667 val_loss: 0.20716\n",
            "Epoch[8740/10000], loss: 0.22440, acc: 0.90667 val_loss: 0.20707\n",
            "Epoch[8750/10000], loss: 0.22432, acc: 0.90667 val_loss: 0.20699\n",
            "Epoch[8760/10000], loss: 0.22425, acc: 0.90667 val_loss: 0.20691\n",
            "Epoch[8770/10000], loss: 0.22417, acc: 0.90667 val_loss: 0.20683\n",
            "Epoch[8780/10000], loss: 0.22410, acc: 0.90667 val_loss: 0.20675\n",
            "Epoch[8790/10000], loss: 0.22402, acc: 0.90667 val_loss: 0.20667\n",
            "Epoch[8800/10000], loss: 0.22395, acc: 0.90667 val_loss: 0.20659\n",
            "Epoch[8810/10000], loss: 0.22387, acc: 0.90667 val_loss: 0.20651\n",
            "Epoch[8820/10000], loss: 0.22380, acc: 0.90667 val_loss: 0.20643\n",
            "Epoch[8830/10000], loss: 0.22372, acc: 0.90667 val_loss: 0.20635\n",
            "Epoch[8840/10000], loss: 0.22365, acc: 0.90667 val_loss: 0.20627\n",
            "Epoch[8850/10000], loss: 0.22357, acc: 0.90667 val_loss: 0.20619\n",
            "Epoch[8860/10000], loss: 0.22350, acc: 0.90667 val_loss: 0.20611\n",
            "Epoch[8870/10000], loss: 0.22342, acc: 0.90667 val_loss: 0.20603\n",
            "Epoch[8880/10000], loss: 0.22335, acc: 0.90667 val_loss: 0.20595\n",
            "Epoch[8890/10000], loss: 0.22327, acc: 0.90667 val_loss: 0.20587\n",
            "Epoch[8900/10000], loss: 0.22320, acc: 0.90667 val_loss: 0.20579\n",
            "Epoch[8910/10000], loss: 0.22313, acc: 0.90667 val_loss: 0.20571\n",
            "Epoch[8920/10000], loss: 0.22305, acc: 0.90667 val_loss: 0.20563\n",
            "Epoch[8930/10000], loss: 0.22298, acc: 0.90667 val_loss: 0.20556\n",
            "Epoch[8940/10000], loss: 0.22291, acc: 0.90667 val_loss: 0.20548\n",
            "Epoch[8950/10000], loss: 0.22283, acc: 0.90667 val_loss: 0.20540\n",
            "Epoch[8960/10000], loss: 0.22276, acc: 0.90667 val_loss: 0.20532\n",
            "Epoch[8970/10000], loss: 0.22269, acc: 0.90667 val_loss: 0.20524\n",
            "Epoch[8980/10000], loss: 0.22261, acc: 0.90667 val_loss: 0.20517\n",
            "Epoch[8990/10000], loss: 0.22254, acc: 0.90667 val_loss: 0.20509\n",
            "Epoch[9000/10000], loss: 0.22247, acc: 0.90667 val_loss: 0.20501\n",
            "Epoch[9010/10000], loss: 0.22240, acc: 0.90667 val_loss: 0.20493\n",
            "Epoch[9020/10000], loss: 0.22232, acc: 0.90667 val_loss: 0.20485\n",
            "Epoch[9030/10000], loss: 0.22225, acc: 0.90667 val_loss: 0.20478\n",
            "Epoch[9040/10000], loss: 0.22218, acc: 0.90667 val_loss: 0.20470\n",
            "Epoch[9050/10000], loss: 0.22211, acc: 0.90667 val_loss: 0.20462\n",
            "Epoch[9060/10000], loss: 0.22204, acc: 0.90667 val_loss: 0.20455\n",
            "Epoch[9070/10000], loss: 0.22196, acc: 0.90667 val_loss: 0.20447\n",
            "Epoch[9080/10000], loss: 0.22189, acc: 0.90667 val_loss: 0.20439\n",
            "Epoch[9090/10000], loss: 0.22182, acc: 0.90667 val_loss: 0.20432\n",
            "Epoch[9100/10000], loss: 0.22175, acc: 0.90667 val_loss: 0.20424\n",
            "Epoch[9110/10000], loss: 0.22168, acc: 0.90667 val_loss: 0.20416\n",
            "Epoch[9120/10000], loss: 0.22161, acc: 0.90667 val_loss: 0.20409\n",
            "Epoch[9130/10000], loss: 0.22154, acc: 0.90667 val_loss: 0.20401\n",
            "Epoch[9140/10000], loss: 0.22147, acc: 0.90667 val_loss: 0.20394\n",
            "Epoch[9150/10000], loss: 0.22140, acc: 0.90667 val_loss: 0.20386\n",
            "Epoch[9160/10000], loss: 0.22133, acc: 0.90667 val_loss: 0.20379\n",
            "Epoch[9170/10000], loss: 0.22126, acc: 0.90667 val_loss: 0.20371\n",
            "Epoch[9180/10000], loss: 0.22118, acc: 0.90667 val_loss: 0.20364\n",
            "Epoch[9190/10000], loss: 0.22111, acc: 0.90667 val_loss: 0.20356\n",
            "Epoch[9200/10000], loss: 0.22105, acc: 0.90667 val_loss: 0.20349\n",
            "Epoch[9210/10000], loss: 0.22098, acc: 0.90667 val_loss: 0.20341\n",
            "Epoch[9220/10000], loss: 0.22091, acc: 0.90667 val_loss: 0.20334\n",
            "Epoch[9230/10000], loss: 0.22084, acc: 0.90667 val_loss: 0.20326\n",
            "Epoch[9240/10000], loss: 0.22077, acc: 0.90667 val_loss: 0.20319\n",
            "Epoch[9250/10000], loss: 0.22070, acc: 0.90667 val_loss: 0.20311\n",
            "Epoch[9260/10000], loss: 0.22063, acc: 0.90667 val_loss: 0.20304\n",
            "Epoch[9270/10000], loss: 0.22056, acc: 0.90667 val_loss: 0.20296\n",
            "Epoch[9280/10000], loss: 0.22049, acc: 0.90667 val_loss: 0.20289\n",
            "Epoch[9290/10000], loss: 0.22042, acc: 0.90667 val_loss: 0.20282\n",
            "Epoch[9300/10000], loss: 0.22035, acc: 0.90667 val_loss: 0.20274\n",
            "Epoch[9310/10000], loss: 0.22028, acc: 0.90667 val_loss: 0.20267\n",
            "Epoch[9320/10000], loss: 0.22022, acc: 0.90667 val_loss: 0.20260\n",
            "Epoch[9330/10000], loss: 0.22015, acc: 0.90667 val_loss: 0.20252\n",
            "Epoch[9340/10000], loss: 0.22008, acc: 0.90667 val_loss: 0.20245\n",
            "Epoch[9350/10000], loss: 0.22001, acc: 0.90667 val_loss: 0.20238\n",
            "Epoch[9360/10000], loss: 0.21994, acc: 0.90667 val_loss: 0.20230\n",
            "Epoch[9370/10000], loss: 0.21988, acc: 0.90667 val_loss: 0.20223\n",
            "Epoch[9380/10000], loss: 0.21981, acc: 0.90667 val_loss: 0.20216\n",
            "Epoch[9390/10000], loss: 0.21974, acc: 0.90667 val_loss: 0.20209\n",
            "Epoch[9400/10000], loss: 0.21967, acc: 0.90667 val_loss: 0.20201\n",
            "Epoch[9410/10000], loss: 0.21961, acc: 0.90667 val_loss: 0.20194\n",
            "Epoch[9420/10000], loss: 0.21954, acc: 0.90667 val_loss: 0.20187\n",
            "Epoch[9430/10000], loss: 0.21947, acc: 0.90667 val_loss: 0.20180\n",
            "Epoch[9440/10000], loss: 0.21940, acc: 0.90667 val_loss: 0.20173\n",
            "Epoch[9450/10000], loss: 0.21934, acc: 0.90667 val_loss: 0.20165\n",
            "Epoch[9460/10000], loss: 0.21927, acc: 0.90667 val_loss: 0.20158\n",
            "Epoch[9470/10000], loss: 0.21920, acc: 0.90667 val_loss: 0.20151\n",
            "Epoch[9480/10000], loss: 0.21914, acc: 0.90667 val_loss: 0.20144\n",
            "Epoch[9490/10000], loss: 0.21907, acc: 0.90667 val_loss: 0.20137\n",
            "Epoch[9500/10000], loss: 0.21901, acc: 0.90667 val_loss: 0.20130\n",
            "Epoch[9510/10000], loss: 0.21894, acc: 0.90667 val_loss: 0.20123\n",
            "Epoch[9520/10000], loss: 0.21887, acc: 0.90667 val_loss: 0.20115\n",
            "Epoch[9530/10000], loss: 0.21881, acc: 0.90667 val_loss: 0.20108\n",
            "Epoch[9540/10000], loss: 0.21874, acc: 0.90667 val_loss: 0.20101\n",
            "Epoch[9550/10000], loss: 0.21868, acc: 0.90667 val_loss: 0.20094\n",
            "Epoch[9560/10000], loss: 0.21861, acc: 0.90667 val_loss: 0.20087\n",
            "Epoch[9570/10000], loss: 0.21854, acc: 0.90667 val_loss: 0.20080\n",
            "Epoch[9580/10000], loss: 0.21848, acc: 0.90667 val_loss: 0.20073\n",
            "Epoch[9590/10000], loss: 0.21841, acc: 0.90667 val_loss: 0.20066\n",
            "Epoch[9600/10000], loss: 0.21835, acc: 0.90667 val_loss: 0.20059\n",
            "Epoch[9610/10000], loss: 0.21828, acc: 0.90667 val_loss: 0.20052\n",
            "Epoch[9620/10000], loss: 0.21822, acc: 0.90667 val_loss: 0.20045\n",
            "Epoch[9630/10000], loss: 0.21815, acc: 0.90667 val_loss: 0.20038\n",
            "Epoch[9640/10000], loss: 0.21809, acc: 0.90667 val_loss: 0.20031\n",
            "Epoch[9650/10000], loss: 0.21803, acc: 0.90667 val_loss: 0.20024\n",
            "Epoch[9660/10000], loss: 0.21796, acc: 0.90667 val_loss: 0.20017\n",
            "Epoch[9670/10000], loss: 0.21790, acc: 0.90667 val_loss: 0.20010\n",
            "Epoch[9680/10000], loss: 0.21783, acc: 0.90667 val_loss: 0.20004\n",
            "Epoch[9690/10000], loss: 0.21777, acc: 0.90667 val_loss: 0.19997\n",
            "Epoch[9700/10000], loss: 0.21770, acc: 0.90667 val_loss: 0.19990\n",
            "Epoch[9710/10000], loss: 0.21764, acc: 0.90667 val_loss: 0.19983\n",
            "Epoch[9720/10000], loss: 0.21758, acc: 0.90667 val_loss: 0.19976\n",
            "Epoch[9730/10000], loss: 0.21751, acc: 0.90667 val_loss: 0.19969\n",
            "Epoch[9740/10000], loss: 0.21745, acc: 0.90667 val_loss: 0.19962\n",
            "Epoch[9750/10000], loss: 0.21739, acc: 0.90667 val_loss: 0.19956\n",
            "Epoch[9760/10000], loss: 0.21732, acc: 0.90667 val_loss: 0.19949\n",
            "Epoch[9770/10000], loss: 0.21726, acc: 0.90667 val_loss: 0.19942\n",
            "Epoch[9780/10000], loss: 0.21720, acc: 0.90667 val_loss: 0.19935\n",
            "Epoch[9790/10000], loss: 0.21713, acc: 0.90667 val_loss: 0.19928\n",
            "Epoch[9800/10000], loss: 0.21707, acc: 0.90667 val_loss: 0.19922\n",
            "Epoch[9810/10000], loss: 0.21701, acc: 0.90667 val_loss: 0.19915\n",
            "Epoch[9820/10000], loss: 0.21695, acc: 0.90667 val_loss: 0.19908\n",
            "Epoch[9830/10000], loss: 0.21688, acc: 0.90667 val_loss: 0.19901\n",
            "Epoch[9840/10000], loss: 0.21682, acc: 0.90667 val_loss: 0.19895\n",
            "Epoch[9850/10000], loss: 0.21676, acc: 0.90667 val_loss: 0.19888\n",
            "Epoch[9860/10000], loss: 0.21670, acc: 0.90667 val_loss: 0.19881\n",
            "Epoch[9870/10000], loss: 0.21663, acc: 0.90667 val_loss: 0.19874\n",
            "Epoch[9880/10000], loss: 0.21657, acc: 0.90667 val_loss: 0.19868\n",
            "Epoch[9890/10000], loss: 0.21651, acc: 0.90667 val_loss: 0.19861\n",
            "Epoch[9900/10000], loss: 0.21645, acc: 0.90667 val_loss: 0.19854\n",
            "Epoch[9910/10000], loss: 0.21639, acc: 0.90667 val_loss: 0.19848\n",
            "Epoch[9920/10000], loss: 0.21633, acc: 0.90667 val_loss: 0.19841\n",
            "Epoch[9930/10000], loss: 0.21626, acc: 0.90667 val_loss: 0.19835\n",
            "Epoch[9940/10000], loss: 0.21620, acc: 0.90667 val_loss: 0.19828\n",
            "Epoch[9950/10000], loss: 0.21614, acc: 0.90667 val_loss: 0.19821\n",
            "Epoch[9960/10000], loss: 0.21608, acc: 0.90667 val_loss: 0.19815\n",
            "Epoch[9970/10000], loss: 0.21602, acc: 0.90667 val_loss: 0.19808\n",
            "Epoch[9980/10000], loss: 0.21596, acc: 0.90667 val_loss: 0.19802\n",
            "Epoch[9990/10000], loss: 0.21590, acc: 0.90667 val_loss: 0.19795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#結果確認\n",
        "print(f'初期状態:損失:{history[0,3]:.5f} 精度: {history[0,4]:.5f}')\n",
        "print(f'最終状態:損失:{history[-1,3]:.5f} 精度: {history[-1,4]:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B-FR1V3P_lK",
        "outputId": "54d4a74e-d01d-475e-ec19-19bfe4fb10c5"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "初期状態:損失:1.09263 精度: 0.26667\n",
            "最終状態:損失:0.19795 精度: 0.96000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線の表示 (損失)\n",
        "\n",
        "plt.plot(history[:,0], history[:,1], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,3], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('損失')\n",
        "plt.title('学習曲線(損失)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "PixdF7plQpkD",
        "outputId": "00bf2dbc-fd44-4784-a588-af29fa92df95"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習曲線の表示 (精度)\n",
        "\n",
        "plt.plot(history[:,0], history[:,2], 'b', label='訓練')\n",
        "plt.plot(history[:,0], history[:,4], 'k', label='検証')\n",
        "plt.xlabel('繰り返し回数')\n",
        "plt.ylabel('精度')\n",
        "plt.title('学習曲線(精度)')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "XSahVRwyRNAD",
        "outputId": "83f2e93a-60d2-48a5-f2bf-3e49fad1ab95"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#モデルへの入力と出力の確認\n",
        "print(labels[0:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cru8h7PPSkUd",
        "outputId": "2936e290-a024-44cc-89c8-800e4d650d6c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 0, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#街頭する入力値を抽出\n",
        "i3 = inputs[0:4,:]\n",
        "print(i3.data.numpy())"
      ],
      "metadata": {
        "id": "Chvw9RkPxGRc",
        "outputId": "534042fc-af5e-4f32-873c-dada6e40819a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.3 4.7]\n",
            " [7.  4.7]\n",
            " [5.  1.6]\n",
            " [6.4 5.6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#出力値にsoftmax関数をかけた結果を取得\n",
        "softmax = torch.nn.Softmax(dim=1)\n",
        "o3 = net(i3)\n",
        "k3 = softmax(o3)\n",
        "print(o3.data.numpy())\n",
        "print()\n",
        "print(k3.data.numpy())"
      ],
      "metadata": {
        "id": "wMano7ZHxYyA",
        "outputId": "31b09ee5-d82b-4b8c-8aa3-1ed197dfa128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 8.8071 14.1937 12.9986]\n",
            " [10.9387 15.1439 12.0167]\n",
            " [12.8262  9.8     0.1734]\n",
            " [ 6.7954 15.0928 17.1111]]\n",
            "\n",
            "[[0.0035 0.765  0.2315]\n",
            " [0.0141 0.9445 0.0414]\n",
            " [0.9537 0.0463 0.    ]\n",
            " [0.     0.1173 0.8827]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#最終的な重み行列とバイアスの値\n",
        "print(net.l1.weight.data)\n",
        "\n",
        "print(net.l1.bias.data)"
      ],
      "metadata": {
        "id": "ib4qIhecxtBP",
        "outputId": "12687b42-3f6a-44d1-ec57-fa7465c791a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 3.0452, -2.5735],\n",
            "        [ 1.3573,  0.8481],\n",
            "        [-1.4026,  4.7253]])\n",
            "tensor([ 1.7178,  1.6563, -0.3741])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ipNpTLaNyGvd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}